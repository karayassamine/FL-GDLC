{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: cic_ton_iot\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from src.data.dataset_info import datasets\n",
    "from src.models import MyCNN, MyLSTM, MyGRU, MyDenseNN\n",
    "# from src.models.dense_nn import  MyDenseNN\n",
    "\n",
    "multi_class = True\n",
    "with_network_features = False\n",
    "\n",
    "with_sort_timestamp = True\n",
    "sequence_length = 3\n",
    "with_cross_validation = True\n",
    "cross_validation_splits_num = 5\n",
    "\n",
    "dataset = datasets[0]\n",
    "name = dataset.name\n",
    "print(\"dataset: {}\".format(name))\n",
    "path = \"./datasets/preprocessed/{}.pkl\".format(name)\n",
    "# graph_path = \"./datasets/preprocessed/graph_{}.gexf\".format(name)\n",
    "df = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> dataset_name: cic_ton_iot\n"
     ]
    }
   ],
   "source": [
    "input_dim = df.shape[1] - len(dataset.drop_columns) - len(dataset.weak_columns) - 1  # for the label_column\n",
    "\n",
    "if not with_network_features:\n",
    "    input_dim = input_dim - len(dataset.network_features)\n",
    "\n",
    "num_classes = 2\n",
    "if multi_class:\n",
    "    num_classes = len(df[\"Attack\"].unique())\n",
    "\n",
    "num_epochs = 50\n",
    "    \n",
    "dropped_columns = dataset.drop_columns\n",
    "dataset_name = dataset.name\n",
    "print(f\"==>> dataset_name: {dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_mixed_samples(data, labels, sequence_length):\n",
    "    \"\"\"\n",
    "    Generate both sequential and non-sequential samples for training various models.\n",
    "\n",
    "    Parameters:\n",
    "    - data: The time series data as a 1D numpy array.\n",
    "    - labels: The corresponding labels for each data point.\n",
    "    - sequence_length: The length of each sequential sample.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing three numpy arrays:\n",
    "      1. Sequential samples: 3D array representing sequential samples.\n",
    "      2. Non-sequential samples: 2D array representing non-sequential samples.\n",
    "      3. Associated labels: 1D array containing labels corresponding to each sample.\n",
    "    \"\"\"\n",
    "    sequential_samples = []\n",
    "    non_sequential_samples = []\n",
    "    associated_labels = []\n",
    "    data_len = len(data)\n",
    "\n",
    "    for i in range(data_len - sequence_length + 1):\n",
    "        # Sequential samples\n",
    "        seq = data[i:i+sequence_length]\n",
    "        sequential_samples.append(seq)\n",
    "        associated_labels.append(labels[i + sequence_length - 1])\n",
    "\n",
    "        # Non-sequential samples (individual data points)\n",
    "        non_seq = data[i + sequence_length - 1]\n",
    "        non_sequential_samples.append(non_seq)\n",
    "\n",
    "    return (\n",
    "        np.array(sequential_samples),\n",
    "        np.array(non_sequential_samples),\n",
    "        np.array(associated_labels)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = []\n",
    "if with_network_features:\n",
    "    nf = dataset.network_features\n",
    "\n",
    "models = [\n",
    "    MyDenseNN(\n",
    "        input_dim=input_dim,\n",
    "        dataset_name=dataset_name,\n",
    "        num_classes=num_classes,\n",
    "        multi_class=multi_class,\n",
    "        network_features=nf,\n",
    "        epochs=num_epochs,\n",
    "        batch_size=256,\n",
    "        early_stop_patience=10\n",
    "    ),\n",
    "    # MyCNN(\n",
    "    #     input_dim=input_dim,\n",
    "    #     dataset_name=dataset_name,\n",
    "    #     num_classes=num_classes,\n",
    "    #     multi_class=multi_class,\n",
    "    #     network_features=nf,\n",
    "    #     epochs=num_epochs,\n",
    "    #     batch_size=256,\n",
    "        # early_stop_patience=10,\n",
    "    # ),\n",
    "    # MyLSTM(\n",
    "    #     sequence_length=sequence_length,\n",
    "    #     input_dim=input_dim,\n",
    "    #     dataset_name=dataset_name,\n",
    "    #     num_classes=num_classes,\n",
    "    #     multi_class=multi_class,\n",
    "    #     network_features=nf,\n",
    "    #     use_generator=True,\n",
    "    #     epochs=num_epochs,\n",
    "    #     batch_size=256,,\n",
    "        # early_stop_patience=10,\n",
    "    # ),\n",
    "    # MyGRU(\n",
    "    #     sequence_length=sequence_length,\n",
    "    #     input_dim=input_dim,\n",
    "    #     dataset_name=dataset_name,\n",
    "    #     num_classes=num_classes,\n",
    "    #     multi_class=multi_class,\n",
    "    #     network_features=nf,\n",
    "    #     use_generator=True,\n",
    "    #     epochs=num_epochs,\n",
    "    #     batch_size=256,,\n",
    "        # early_stop_patience=10,\n",
    "    # )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}  # a dictionary that will contain all the options and results of models\n",
    "# add all options to the results dictionary, to know what options selected for obtained results\n",
    "results[\"configuration\"] = \"stratified k-fold cross validation - manual sequences\"\n",
    "results[\"multi_class\"] = multi_class\n",
    "results[\"with_sort_timestamp\"] = with_sort_timestamp\n",
    "results[\"sequence_length\"] = sequence_length\n",
    "results[\"with_cross_validation\"] = with_cross_validation\n",
    "results[\"cross_validation_splits_num\"] = cross_validation_splits_num\n",
    "results[\"with_network_features\"] = with_network_features\n",
    "results[\"network_features\"] = dataset.cn_measures\n",
    "\n",
    "results[\"dataset_name\"] = dataset_name\n",
    "results[\"input_dim\"] = input_dim\n",
    "results[\"dropped_columns\"] = dropped_columns\n",
    "results[\"num_dropped_columns\"] = len(dropped_columns)\n",
    "\n",
    "results[\"models\"] = {}\n",
    "results[\"average_acc\"] = {}\n",
    "results[\"average\"] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> labels_names: {0: 'Benign', 1: 'xss', 2: 'password', 3: 'scanning', 4: 'injection', 5: 'ransomware', 6: 'backdoor', 7: 'mitm', 8: 'ddos', 9: 'dos'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if with_sort_timestamp:\n",
    "    df[dataset.timestamp_col] = pd.to_datetime(df[dataset.timestamp_col].str.strip(), format=dataset.timestamp_format)\n",
    "\n",
    "    # sorted_grouped = df.sort_values(\n",
    "    #     self.datasetInfo.timestamp_col).groupby(self.datasetInfo.src_ip_col)\n",
    "\n",
    "    # sorted_grouped = df.sort_values(\n",
    "    #     self.datasetInfo.timestamp_col).groupby(self.datasetInfo.dst_ip_col)\n",
    "\n",
    "    # df = pd.concat([group for _, group in sorted_grouped])\n",
    "\n",
    "    df.sort_values(dataset.timestamp_col, inplace= True)\n",
    "\n",
    "labels_names = {0: \"benign\", 1: \"attack\"}\n",
    "if multi_class:\n",
    "    fac = pd.factorize(df[dataset.class_col])\n",
    "    labels_names = {index: value for index, value in enumerate(fac[1])}\n",
    "    print(f\"==>> labels_names: {labels_names}\")\n",
    "    df[dataset.label_col] = fac[0]  # type: ignore\n",
    "\n",
    "\n",
    "df.drop(dataset.drop_columns, axis=1, inplace=True)\n",
    "df.drop(dataset.weak_columns, axis=1, inplace=True)\n",
    "\n",
    "if not with_network_features:\n",
    "    df = df.drop(dataset.network_features, axis=1)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>Bwd Pkt Len Min</th>\n",
       "      <th>Flow Byts/s</th>\n",
       "      <th>Flow IAT Std</th>\n",
       "      <th>Fwd IAT Max</th>\n",
       "      <th>Fwd IAT Min</th>\n",
       "      <th>Bwd IAT Std</th>\n",
       "      <th>...</th>\n",
       "      <th>Init Fwd Win Byts</th>\n",
       "      <th>Init Bwd Win Byts</th>\n",
       "      <th>Fwd Act Data Pkts</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.306497e+07</td>\n",
       "      <td>102196170.0</td>\n",
       "      <td>13008834.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.973171e+14</td>\n",
       "      <td>1.554199e+15</td>\n",
       "      <td>1.300883e+07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.373953e+06</td>\n",
       "      <td>3991265.0</td>\n",
       "      <td>2048202.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.554199e+15</td>\n",
       "      <td>1.554199e+15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.564027e+07</td>\n",
       "      <td>43827824.0</td>\n",
       "      <td>21709138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.973172e+14</td>\n",
       "      <td>1.554199e+15</td>\n",
       "      <td>2.170914e+07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.231300e+07</td>\n",
       "      <td>75008320.0</td>\n",
       "      <td>15168707.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.973172e+14</td>\n",
       "      <td>1.554199e+15</td>\n",
       "      <td>1.516871e+07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.880029e+06</td>\n",
       "      <td>57137762.0</td>\n",
       "      <td>54478999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.973172e+14</td>\n",
       "      <td>1.554199e+15</td>\n",
       "      <td>5.447900e+07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Protocol  Tot Fwd Pkts  TotLen Fwd Pkts  Fwd Pkt Len Min  Bwd Pkt Len Min  \\\n",
       "0       0.0           3.0              0.0              0.0              0.0   \n",
       "1       0.0           3.0              0.0              0.0              0.0   \n",
       "2       0.0           3.0              0.0              0.0              0.0   \n",
       "3       0.0           3.0              0.0              0.0              0.0   \n",
       "4       0.0           3.0              0.0              0.0              0.0   \n",
       "\n",
       "   Flow Byts/s  Flow IAT Std  Fwd IAT Max  Fwd IAT Min  Bwd IAT Std  ...  \\\n",
       "0          0.0  6.306497e+07  102196170.0   13008834.0          0.0  ...   \n",
       "1          0.0  1.373953e+06    3991265.0    2048202.0          0.0  ...   \n",
       "2          0.0  1.564027e+07   43827824.0   21709138.0          0.0  ...   \n",
       "3          0.0  4.231300e+07   75008320.0   15168707.0          0.0  ...   \n",
       "4          0.0  1.880029e+06   57137762.0   54478999.0          0.0  ...   \n",
       "\n",
       "   Init Fwd Win Byts  Init Bwd Win Byts  Fwd Act Data Pkts  Fwd Seg Size Min  \\\n",
       "0                0.0                0.0                0.0               0.0   \n",
       "1                0.0                0.0                0.0               0.0   \n",
       "2                0.0                0.0                0.0               0.0   \n",
       "3                0.0                0.0                0.0               0.0   \n",
       "4                0.0                0.0                0.0               0.0   \n",
       "\n",
       "   Active Max  Active Min      Idle Std      Idle Max      Idle Min  Label  \n",
       "0         0.0         0.0  8.973171e+14  1.554199e+15  1.300883e+07      0  \n",
       "1         0.0         0.0  0.000000e+00  1.554199e+15  1.554199e+15      0  \n",
       "2         0.0         0.0  8.973172e+14  1.554199e+15  2.170914e+07      0  \n",
       "3         0.0         0.0  8.973172e+14  1.554199e+15  1.516871e+07      0  \n",
       "4         0.0         0.0  8.973172e+14  1.554199e+15  5.447900e+07      0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['Label'].to_numpy()\n",
    "df = df.drop([dataset.label_col], axis=1).to_numpy()\n",
    "\n",
    "isThereLSTM = False\n",
    "if isThereLSTM:\n",
    "    df, df_non_seq, labels = create_mixed_samples(\n",
    "        df, labels, sequence_length)\n",
    "else:\n",
    "    df_non_seq = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> train_index: [      0       1       2 ... 5350579 5350580 5350581]\n",
      "==>> training_labels: (4280466,)\n",
      "==>> test_index: [     10      23      28 ... 5350573 5350578 5350582]\n",
      "==>> testing_labels: (1070117,)\n",
      "fold: 1\n",
      "=====================================\n",
      "=====================================\n",
      "fold: 1/5\n",
      "training: dense_nn mc \n",
      "sequential: False\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizatio  (None, 37)               75        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 500)               19000     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                5010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 775,585\n",
      "Trainable params: 775,510\n",
      "Non-trainable params: 75\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "16721/16721 [==============================] - 339s 20ms/step - loss: 0.3877 - accuracy: 0.8578\n",
      "Epoch 2/50\n",
      "16721/16721 [==============================] - 341s 20ms/step - loss: 0.3635 - accuracy: 0.8617\n",
      "Epoch 3/50\n",
      "16721/16721 [==============================] - 346s 21ms/step - loss: 0.3579 - accuracy: 0.8626\n",
      "Epoch 4/50\n",
      "16721/16721 [==============================] - 352s 21ms/step - loss: 0.3553 - accuracy: 0.8631\n",
      "Epoch 5/50\n",
      "16721/16721 [==============================] - 349s 21ms/step - loss: 0.3533 - accuracy: 0.8633\n",
      "Epoch 6/50\n",
      "16721/16721 [==============================] - 351s 21ms/step - loss: 0.3524 - accuracy: 0.8635\n",
      "Epoch 7/50\n",
      "16721/16721 [==============================] - 351s 21ms/step - loss: 0.3534 - accuracy: 0.8637\n",
      "Epoch 8/50\n",
      "16721/16721 [==============================] - 353s 21ms/step - loss: 0.3544 - accuracy: 0.8638\n",
      "Epoch 9/50\n",
      "16721/16721 [==============================] - 350s 21ms/step - loss: 0.3492 - accuracy: 0.8639\n",
      "Epoch 10/50\n",
      "16721/16721 [==============================] - 350s 21ms/step - loss: 0.3486 - accuracy: 0.8640\n",
      "Epoch 11/50\n",
      "16721/16721 [==============================] - 350s 21ms/step - loss: 0.3496 - accuracy: 0.8640\n",
      "Epoch 12/50\n",
      "16721/16721 [==============================] - 350s 21ms/step - loss: 0.3498 - accuracy: 0.8642\n",
      "Epoch 13/50\n",
      "16721/16721 [==============================] - 347s 21ms/step - loss: 0.3475 - accuracy: 0.8642\n",
      "Epoch 14/50\n",
      "16721/16721 [==============================] - 360s 22ms/step - loss: 0.3471 - accuracy: 0.8642\n",
      "Epoch 15/50\n",
      "16721/16721 [==============================] - 360s 22ms/step - loss: 0.3475 - accuracy: 0.8642\n",
      "Epoch 16/50\n",
      "16721/16721 [==============================] - 360s 22ms/step - loss: 0.3463 - accuracy: 0.8642\n",
      "Epoch 17/50\n",
      "16721/16721 [==============================] - 355s 21ms/step - loss: 0.3486 - accuracy: 0.8643\n",
      "Epoch 18/50\n",
      "16721/16721 [==============================] - 356s 21ms/step - loss: 0.3465 - accuracy: 0.8643\n",
      "Epoch 19/50\n",
      "16721/16721 [==============================] - 351s 21ms/step - loss: 0.3511 - accuracy: 0.8643\n",
      "Epoch 20/50\n",
      "16721/16721 [==============================] - 352s 21ms/step - loss: 0.3645 - accuracy: 0.8644\n",
      "Epoch 21/50\n",
      "16721/16721 [==============================] - 353s 21ms/step - loss: 0.3459 - accuracy: 0.8643\n",
      "Epoch 22/50\n",
      "16721/16721 [==============================] - 353s 21ms/step - loss: 0.3452 - accuracy: 0.8644\n",
      "Epoch 23/50\n",
      "16721/16721 [==============================] - 350s 21ms/step - loss: 0.3494 - accuracy: 0.8643\n",
      "Epoch 24/50\n",
      "16721/16721 [==============================] - 353s 21ms/step - loss: 0.3650 - accuracy: 0.8643\n",
      "Epoch 25/50\n",
      "16721/16721 [==============================] - 351s 21ms/step - loss: 0.3451 - accuracy: 0.8645\n",
      "Epoch 26/50\n",
      "16721/16721 [==============================] - 348s 21ms/step - loss: 0.3451 - accuracy: 0.8644\n",
      "Epoch 27/50\n",
      "16721/16721 [==============================] - 343s 21ms/step - loss: 0.3450 - accuracy: 0.8644\n",
      "Epoch 28/50\n",
      "16721/16721 [==============================] - 346s 21ms/step - loss: 0.3441 - accuracy: 0.8644\n",
      "Epoch 29/50\n",
      "16721/16721 [==============================] - 347s 21ms/step - loss: 0.6216 - accuracy: 0.8643\n",
      "Epoch 30/50\n",
      "16721/16721 [==============================] - 340s 20ms/step - loss: 0.3454 - accuracy: 0.8645\n",
      "Epoch 31/50\n",
      "16721/16721 [==============================] - 347s 21ms/step - loss: 0.3472 - accuracy: 0.8645\n",
      "Epoch 32/50\n",
      "16721/16721 [==============================] - 342s 20ms/step - loss: 0.3455 - accuracy: 0.8644\n",
      "Epoch 33/50\n",
      "16721/16721 [==============================] - 347s 21ms/step - loss: 0.3440 - accuracy: 0.8645\n",
      "Epoch 34/50\n",
      "16721/16721 [==============================] - 357s 21ms/step - loss: 0.3436 - accuracy: 0.8645\n",
      "Epoch 35/50\n",
      "16721/16721 [==============================] - 364s 22ms/step - loss: 0.3480 - accuracy: 0.8645\n",
      "Epoch 36/50\n",
      "16721/16721 [==============================] - 361s 22ms/step - loss: 0.3483 - accuracy: 0.8645\n",
      "Epoch 37/50\n",
      "16721/16721 [==============================] - 359s 21ms/step - loss: 0.3446 - accuracy: 0.8645\n",
      "Epoch 38/50\n",
      "16721/16721 [==============================] - 359s 21ms/step - loss: 0.3512 - accuracy: 0.8645\n",
      "Epoch 39/50\n",
      "16721/16721 [==============================] - 355s 21ms/step - loss: 0.3633 - accuracy: 0.8644\n",
      "Epoch 40/50\n",
      "16721/16721 [==============================] - 361s 22ms/step - loss: 0.3459 - accuracy: 0.8644\n",
      "Epoch 41/50\n",
      "16721/16721 [==============================] - 360s 22ms/step - loss: 0.3510 - accuracy: 0.8644\n",
      "Epoch 42/50\n",
      "16721/16721 [==============================] - 360s 22ms/step - loss: 0.3441 - accuracy: 0.8645\n",
      "Epoch 43/50\n",
      "16721/16721 [==============================] - 359s 21ms/step - loss: 0.3448 - accuracy: 0.8644\n",
      "Epoch 44/50\n",
      "16721/16721 [==============================] - 346s 21ms/step - loss: 0.3451 - accuracy: 0.8645\n",
      "4181/4181 [==============================] - 33s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:\n",
      "[[494842   7802     10      0     40    113      3      2      0      0]\n",
      " [  5971 420810   1078     77   1926      0      0      0      0      0]\n",
      " [   825  65729   1111     31    345      0      0      0      0      0]\n",
      " [   149   6631    364     46     48      0      0      3      0      0]\n",
      " [  1130  52229    137     12   2031      0      0      1      0      0]\n",
      " [    97      1      0      0      0    852     69      0      0      0]\n",
      " [    38      0      0      0      0     27   5363      1      0      0]\n",
      " [    41      0      0      0      0      0      2     61      0      0]\n",
      " [    17      0      0      0      0      0      0     23      0      0]\n",
      " [     9      0      0      0      0      0      0     20      0      0]]\n",
      "End of confusion_matrix:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrateur\\Desktop\\GDLC\\src\\models\\model.py:88: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  class_precision[i] = tp / (tp + fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98    502812\n",
      "           1       0.76      0.98      0.86    429862\n",
      "           2       0.41      0.02      0.03     68041\n",
      "           3       0.28      0.01      0.01      7241\n",
      "           4       0.46      0.04      0.07     55540\n",
      "           5       0.86      0.84      0.85      1019\n",
      "           6       0.99      0.99      0.99      5429\n",
      "           7       0.55      0.59      0.57       104\n",
      "           8       0.00      0.00      0.00        40\n",
      "           9       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.86   1070117\n",
      "   macro avg       0.53      0.44      0.44   1070117\n",
      "weighted avg       0.83      0.86      0.82   1070117\n",
      "\n",
      "End of Classification Report:\n",
      "dense_nn mc : {'accuracy': 0.8644998630990817, 'recall': 0.8644998630990817, 'precision': 0.8256241834073993, 'f1s': 0.8176462859703906, 'FPR': 0.015055570766768701, 'FNR': 0.1355001369009183, 'time': 35.24499297142029, 'fold': 1}\n",
      "dense_nn mc  average accuracy: 0.8644998630990817\n",
      "==>> train_index: [      0       2       3 ... 5350580 5350581 5350582]\n",
      "==>> training_labels: (4280466,)\n",
      "==>> test_index: [      1       7       8 ... 5350569 5350575 5350579]\n",
      "==>> testing_labels: (1070117,)\n",
      "fold: 2\n",
      "=====================================\n",
      "=====================================\n",
      "fold: 2/5\n",
      "training: dense_nn mc \n",
      "sequential: False\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_1 (Normalizat  (None, 37)               75        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 500)               19000     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                5010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 775,585\n",
      "Trainable params: 775,510\n",
      "Non-trainable params: 75\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "16721/16721 [==============================] - 370s 22ms/step - loss: 0.3867 - accuracy: 0.8581\n",
      "Epoch 2/50\n",
      "16721/16721 [==============================] - 369s 22ms/step - loss: 0.3637 - accuracy: 0.8618\n",
      "Epoch 3/50\n",
      "16721/16721 [==============================] - 358s 21ms/step - loss: 0.3588 - accuracy: 0.8625\n",
      "Epoch 4/50\n",
      "16721/16721 [==============================] - 359s 21ms/step - loss: 0.3554 - accuracy: 0.8631\n",
      "Epoch 5/50\n",
      "16721/16721 [==============================] - 361s 22ms/step - loss: 0.3540 - accuracy: 0.8634\n",
      "Epoch 6/50\n",
      "16721/16721 [==============================] - 359s 21ms/step - loss: 0.3546 - accuracy: 0.8635\n",
      "Epoch 7/50\n",
      "16721/16721 [==============================] - 359s 21ms/step - loss: 0.3519 - accuracy: 0.8637\n",
      "Epoch 8/50\n",
      "16721/16721 [==============================] - 362s 22ms/step - loss: 0.3515 - accuracy: 0.8639\n",
      "Epoch 9/50\n",
      "16721/16721 [==============================] - 361s 22ms/step - loss: 0.3508 - accuracy: 0.8640\n",
      "Epoch 10/50\n",
      "16721/16721 [==============================] - 363s 22ms/step - loss: 0.3501 - accuracy: 0.8641\n",
      "Epoch 11/50\n",
      "16721/16721 [==============================] - 362s 22ms/step - loss: 0.3511 - accuracy: 0.8641\n",
      "Epoch 12/50\n",
      "16721/16721 [==============================] - 360s 22ms/step - loss: 0.3479 - accuracy: 0.8641\n",
      "Epoch 13/50\n",
      "16721/16721 [==============================] - 360s 22ms/step - loss: 0.3477 - accuracy: 0.8642\n",
      "Epoch 14/50\n",
      "16721/16721 [==============================] - 357s 21ms/step - loss: 0.3474 - accuracy: 0.8643\n",
      "Epoch 15/50\n",
      "16721/16721 [==============================] - 361s 22ms/step - loss: 0.3475 - accuracy: 0.8644\n",
      "Epoch 16/50\n",
      "16721/16721 [==============================] - 364s 22ms/step - loss: 0.3480 - accuracy: 0.8642\n",
      "Epoch 17/50\n",
      "16721/16721 [==============================] - 362s 22ms/step - loss: 0.3500 - accuracy: 0.8643\n",
      "Epoch 18/50\n",
      "16721/16721 [==============================] - 366s 22ms/step - loss: 0.3470 - accuracy: 0.8644\n",
      "Epoch 19/50\n",
      "16721/16721 [==============================] - 364s 22ms/step - loss: 0.3463 - accuracy: 0.8644\n",
      "Epoch 20/50\n",
      "16721/16721 [==============================] - 368s 22ms/step - loss: 0.3463 - accuracy: 0.8644\n",
      "Epoch 21/50\n",
      "16721/16721 [==============================] - 367s 22ms/step - loss: 0.3573 - accuracy: 0.8644\n",
      "Epoch 22/50\n",
      "16721/16721 [==============================] - 360s 22ms/step - loss: 0.3459 - accuracy: 0.8645\n",
      "Epoch 23/50\n",
      "16721/16721 [==============================] - 361s 22ms/step - loss: 0.3461 - accuracy: 0.8643\n",
      "Epoch 24/50\n",
      "16721/16721 [==============================] - 359s 21ms/step - loss: 0.3448 - accuracy: 0.8645\n",
      "Epoch 25/50\n",
      "16721/16721 [==============================] - 361s 22ms/step - loss: 0.3444 - accuracy: 0.8645\n",
      "Epoch 26/50\n",
      "16721/16721 [==============================] - 359s 21ms/step - loss: 0.3443 - accuracy: 0.8645\n",
      "Epoch 27/50\n",
      "16721/16721 [==============================] - 371s 22ms/step - loss: 0.3451 - accuracy: 0.8645\n",
      "Epoch 28/50\n",
      "16721/16721 [==============================] - 358s 21ms/step - loss: 0.4934 - accuracy: 0.8646\n",
      "Epoch 29/50\n",
      "16721/16721 [==============================] - 354s 21ms/step - loss: 0.3446 - accuracy: 0.8645\n",
      "Epoch 30/50\n",
      "16721/16721 [==============================] - 354s 21ms/step - loss: 0.3512 - accuracy: 0.8645\n",
      "Epoch 31/50\n",
      "16721/16721 [==============================] - 354s 21ms/step - loss: 0.3446 - accuracy: 0.8644\n",
      "Epoch 32/50\n",
      "16721/16721 [==============================] - 354s 21ms/step - loss: 0.3444 - accuracy: 0.8645\n",
      "Epoch 33/50\n",
      "16721/16721 [==============================] - 353s 21ms/step - loss: 0.4240 - accuracy: 0.8646\n",
      "Epoch 34/50\n",
      "16721/16721 [==============================] - 351s 21ms/step - loss: 0.3462 - accuracy: 0.8645\n",
      "Epoch 35/50\n",
      "16721/16721 [==============================] - 348s 21ms/step - loss: 0.3506 - accuracy: 0.8646\n",
      "Epoch 36/50\n",
      "16721/16721 [==============================] - 349s 21ms/step - loss: 0.3428 - accuracy: 0.8646\n",
      "Epoch 37/50\n",
      "16721/16721 [==============================] - 351s 21ms/step - loss: 0.3489 - accuracy: 0.8645\n",
      "Epoch 38/50\n",
      "16721/16721 [==============================] - 351s 21ms/step - loss: 0.3424 - accuracy: 0.8645\n",
      "Epoch 39/50\n",
      "16721/16721 [==============================] - 356s 21ms/step - loss: 0.3425 - accuracy: 0.8645\n",
      "Epoch 40/50\n",
      "16721/16721 [==============================] - 363s 22ms/step - loss: 0.3472 - accuracy: 0.8645\n",
      "Epoch 41/50\n",
      "16721/16721 [==============================] - 362s 22ms/step - loss: 0.3429 - accuracy: 0.8645\n",
      "Epoch 42/50\n",
      "16721/16721 [==============================] - 363s 22ms/step - loss: 0.3452 - accuracy: 0.8642\n",
      "Epoch 43/50\n",
      "16721/16721 [==============================] - 362s 22ms/step - loss: 0.3427 - accuracy: 0.8645\n",
      "Epoch 44/50\n",
      "16721/16721 [==============================] - 352s 21ms/step - loss: 0.3453 - accuracy: 0.8644\n",
      "Epoch 45/50\n",
      "16721/16721 [==============================] - 358s 21ms/step - loss: 0.3435 - accuracy: 0.8642\n",
      "Epoch 46/50\n",
      "16721/16721 [==============================] - 357s 21ms/step - loss: 0.3448 - accuracy: 0.8641\n",
      "Epoch 47/50\n",
      "16721/16721 [==============================] - 357s 21ms/step - loss: 0.6268 - accuracy: 0.8645\n",
      "Epoch 48/50\n",
      "16721/16721 [==============================] - 365s 22ms/step - loss: 0.3470 - accuracy: 0.8644\n",
      "4181/4181 [==============================] - 34s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:\n",
      "[[495381   7344      2      0     69     13      0      3      0      0]\n",
      " [  6144 419803   1018      7   2890      0      0      0      0      0]\n",
      " [   751  66023   1102      6    159      0      0      0      0      0]\n",
      " [   108   6808    295      5     24      0      0      1      0      0]\n",
      " [   942  51527     90      0   2980      0      0      0      0      0]\n",
      " [   136      0      0      0      0    884      0      0      0      0]\n",
      " [    71      0      0      0      0      1   5357      0      0      0]\n",
      " [    67      0      0      0      0      0      0     36      0      0]\n",
      " [    36      0      0      0      0      0      0      5      0      0]\n",
      " [    27      0      0      0      0      0      0      2      0      0]]\n",
      "End of confusion_matrix:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrateur\\Desktop\\GDLC\\src\\models\\model.py:88: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  class_precision[i] = tp / (tp + fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    502812\n",
      "           1       0.76      0.98      0.86    429862\n",
      "           2       0.44      0.02      0.03     68041\n",
      "           3       0.28      0.00      0.00      7241\n",
      "           4       0.49      0.05      0.10     55539\n",
      "           5       0.98      0.87      0.92      1020\n",
      "           6       1.00      0.99      0.99      5429\n",
      "           7       0.77      0.35      0.48       103\n",
      "           8       0.00      0.00      0.00        41\n",
      "           9       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.86   1070117\n",
      "   macro avg       0.57      0.42      0.44   1070117\n",
      "weighted avg       0.83      0.86      0.82   1070117\n",
      "\n",
      "End of Classification Report:\n",
      "dense_nn mc : {'accuracy': 0.8649035572745783, 'recall': 0.8649035572745783, 'precision': 0.829086623842031, 'f1s': 0.8191775395802355, 'FPR': 0.015010715858380179, 'FNR': 0.13509644272542162, 'time': 35.07294678688049, 'fold': 2}\n",
      "dense_nn mc  average accuracy: 0.86470171018683\n",
      "==>> train_index: [      0       1       2 ... 5350579 5350581 5350582]\n",
      "==>> training_labels: (4280466,)\n",
      "==>> test_index: [      4      13      15 ... 5350556 5350577 5350580]\n",
      "==>> testing_labels: (1070117,)\n",
      "fold: 3\n",
      "=====================================\n",
      "=====================================\n",
      "fold: 3/5\n",
      "training: dense_nn mc \n",
      "sequential: False\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_2 (Normalizat  (None, 37)               75        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 500)               19000     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                5010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 775,585\n",
      "Trainable params: 775,510\n",
      "Non-trainable params: 75\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "16721/16721 [==============================] - 363s 22ms/step - loss: 0.3878 - accuracy: 0.8578\n",
      "Epoch 2/50\n",
      "16721/16721 [==============================] - 363s 22ms/step - loss: 0.3634 - accuracy: 0.8619\n",
      "Epoch 3/50\n",
      "16721/16721 [==============================] - 364s 22ms/step - loss: 0.3579 - accuracy: 0.8627\n",
      "Epoch 4/50\n",
      "16721/16721 [==============================] - 366s 22ms/step - loss: 0.3554 - accuracy: 0.8631\n",
      "Epoch 5/50\n",
      "16721/16721 [==============================] - 364s 22ms/step - loss: 0.3535 - accuracy: 0.8634\n",
      "Epoch 6/50\n",
      "16721/16721 [==============================] - 360s 22ms/step - loss: 0.3521 - accuracy: 0.8635\n",
      "Epoch 7/50\n",
      "16721/16721 [==============================] - 364s 22ms/step - loss: 0.3509 - accuracy: 0.8637\n",
      "Epoch 8/50\n",
      "16721/16721 [==============================] - 364s 22ms/step - loss: 0.3504 - accuracy: 0.8638\n",
      "Epoch 9/50\n",
      "16721/16721 [==============================] - 365s 22ms/step - loss: 0.3520 - accuracy: 0.8641\n",
      "Epoch 10/50\n",
      "16721/16721 [==============================] - 365s 22ms/step - loss: 0.3486 - accuracy: 0.8641\n",
      "Epoch 11/50\n",
      "16721/16721 [==============================] - 361s 22ms/step - loss: 0.3482 - accuracy: 0.8641\n",
      "Epoch 12/50\n",
      "16721/16721 [==============================] - 373s 22ms/step - loss: 0.3730 - accuracy: 0.8642\n",
      "Epoch 13/50\n",
      "16721/16721 [==============================] - 378s 23ms/step - loss: 0.3464 - accuracy: 0.8643\n",
      "Epoch 14/50\n",
      "16721/16721 [==============================] - 378s 23ms/step - loss: 0.3501 - accuracy: 0.8642\n",
      "Epoch 15/50\n",
      "16721/16721 [==============================] - 380s 23ms/step - loss: 0.3465 - accuracy: 0.8644\n",
      "Epoch 16/50\n",
      "16721/16721 [==============================] - 375s 22ms/step - loss: 0.3458 - accuracy: 0.8644\n",
      "Epoch 17/50\n",
      "16721/16721 [==============================] - 374s 22ms/step - loss: 0.3457 - accuracy: 0.8643\n",
      "Epoch 18/50\n",
      "16721/16721 [==============================] - 380s 23ms/step - loss: 0.3458 - accuracy: 0.8644\n",
      "Epoch 19/50\n",
      "16721/16721 [==============================] - 382s 23ms/step - loss: 0.3456 - accuracy: 0.8643\n",
      "Epoch 20/50\n",
      "16721/16721 [==============================] - 379s 23ms/step - loss: 0.3458 - accuracy: 0.8645\n",
      "Epoch 21/50\n",
      "16721/16721 [==============================] - 378s 23ms/step - loss: 0.3678 - accuracy: 0.8644\n",
      "Epoch 22/50\n",
      "16721/16721 [==============================] - 373s 22ms/step - loss: 0.3448 - accuracy: 0.8645\n",
      "Epoch 23/50\n",
      "16721/16721 [==============================] - 380s 23ms/step - loss: 0.3441 - accuracy: 0.8646\n",
      "Epoch 24/50\n",
      "16721/16721 [==============================] - 380s 23ms/step - loss: 0.3457 - accuracy: 0.8645\n",
      "Epoch 25/50\n",
      "16721/16721 [==============================] - 380s 23ms/step - loss: 0.3472 - accuracy: 0.8645\n",
      "Epoch 26/50\n",
      "16721/16721 [==============================] - 382s 23ms/step - loss: 0.3441 - accuracy: 0.8645\n",
      "Epoch 27/50\n",
      "16721/16721 [==============================] - 365s 22ms/step - loss: 0.3448 - accuracy: 0.8643\n",
      "Epoch 28/50\n",
      "16721/16721 [==============================] - 374s 22ms/step - loss: 0.3449 - accuracy: 0.8644\n",
      "Epoch 29/50\n",
      "16721/16721 [==============================] - 369s 22ms/step - loss: 0.3490 - accuracy: 0.8645\n",
      "Epoch 30/50\n",
      "16721/16721 [==============================] - 366s 22ms/step - loss: 0.3457 - accuracy: 0.8646\n",
      "Epoch 31/50\n",
      "16721/16721 [==============================] - 365s 22ms/step - loss: 0.3440 - accuracy: 0.8645\n",
      "Epoch 32/50\n",
      "16721/16721 [==============================] - 364s 22ms/step - loss: 0.3438 - accuracy: 0.8646\n",
      "Epoch 33/50\n",
      "16721/16721 [==============================] - 371s 22ms/step - loss: 0.3431 - accuracy: 0.8647\n",
      "Epoch 34/50\n",
      "16721/16721 [==============================] - 369s 22ms/step - loss: 0.3440 - accuracy: 0.8646\n",
      "Epoch 35/50\n",
      "16721/16721 [==============================] - 370s 22ms/step - loss: 0.3476 - accuracy: 0.8644\n",
      "Epoch 36/50\n",
      "16721/16721 [==============================] - 369s 22ms/step - loss: 0.3430 - accuracy: 0.8646\n",
      "Epoch 37/50\n",
      "16721/16721 [==============================] - 367s 22ms/step - loss: 0.3431 - accuracy: 0.8646\n",
      "Epoch 38/50\n",
      "16721/16721 [==============================] - 370s 22ms/step - loss: 0.3530 - accuracy: 0.8646\n",
      "Epoch 39/50\n",
      "16721/16721 [==============================] - 369s 22ms/step - loss: 0.3485 - accuracy: 0.8646\n",
      "Epoch 40/50\n",
      "16721/16721 [==============================] - 369s 22ms/step - loss: 0.3725 - accuracy: 0.8645\n",
      "Epoch 41/50\n",
      "16721/16721 [==============================] - 370s 22ms/step - loss: 0.3425 - accuracy: 0.8643\n",
      "Epoch 42/50\n",
      "16721/16721 [==============================] - 366s 22ms/step - loss: 0.3433 - accuracy: 0.8644\n",
      "Epoch 43/50\n",
      "16721/16721 [==============================] - 364s 22ms/step - loss: 0.3423 - accuracy: 0.8647\n",
      "Epoch 44/50\n",
      "16721/16721 [==============================] - 366s 22ms/step - loss: 0.3427 - accuracy: 0.8646\n",
      "Epoch 45/50\n",
      "16721/16721 [==============================] - 365s 22ms/step - loss: 0.3471 - accuracy: 0.8645\n",
      "Epoch 46/50\n",
      "16721/16721 [==============================] - 366s 22ms/step - loss: 0.3445 - accuracy: 0.8645\n",
      "Epoch 47/50\n",
      "16721/16721 [==============================] - 364s 22ms/step - loss: 0.3436 - accuracy: 0.8645\n",
      "Epoch 48/50\n",
      "16721/16721 [==============================] - 363s 22ms/step - loss: 0.3420 - accuracy: 0.8647\n",
      "Epoch 49/50\n",
      "16721/16721 [==============================] - 368s 22ms/step - loss: 0.3421 - accuracy: 0.8646\n",
      "Epoch 50/50\n",
      "16721/16721 [==============================] - 371s 22ms/step - loss: 0.3433 - accuracy: 0.8645\n",
      "4181/4181 [==============================] - 35s 8ms/step\n",
      "confusion_matrix:\n",
      "[[495617   7083     24      0     73     14      1      0      0      0]\n",
      " [  6439 417194   3994     28   2206      0      0      0      0      0]\n",
      " [   839  63161   3675     19    348      0      0      0      0      0]\n",
      " [   162   6481    520     20     53      0      0      0      4      1]\n",
      " [  1202  50813   1332      2   2189      0      0      0      1      0]\n",
      " [   101      0      0      0      0    919      0      0      0      0]\n",
      " [    71      0      0      0      0     12   5346      0      0      0]\n",
      " [    37      0      0      0      0      0      1     31     33      1]\n",
      " [     6      0      0      0      0      0      0      1     34      0]\n",
      " [     1      0      0      0      0      0      0      0     28      0]]\n",
      "End of confusion_matrix:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    502812\n",
      "           1       0.77      0.97      0.86    429861\n",
      "           2       0.39      0.05      0.09     68042\n",
      "           3       0.29      0.00      0.01      7241\n",
      "           4       0.45      0.04      0.07     55539\n",
      "           5       0.97      0.90      0.94      1020\n",
      "           6       1.00      0.98      0.99      5429\n",
      "           7       0.97      0.30      0.46       103\n",
      "           8       0.34      0.83      0.48        41\n",
      "           9       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.86   1070117\n",
      "   macro avg       0.62      0.51      0.49   1070117\n",
      "weighted avg       0.83      0.86      0.82   1070117\n",
      "\n",
      "End of Classification Report:\n",
      "dense_nn mc : {'accuracy': 0.8644148256685951, 'recall': 0.8644148256685951, 'precision': 0.8251424636197394, 'f1s': 0.8220949541629533, 'FPR': 0.015065019370156097, 'FNR': 0.13558517433140488, 'time': 36.44901132583618, 'fold': 3}\n",
      "dense_nn mc  average accuracy: 0.864606082014085\n",
      "==>> train_index: [      1       4       6 ... 5350580 5350581 5350582]\n",
      "==>> training_labels: (4280467,)\n",
      "==>> test_index: [      0       2       3 ... 5350567 5350571 5350572]\n",
      "==>> testing_labels: (1070116,)\n",
      "fold: 4\n",
      "=====================================\n",
      "=====================================\n",
      "fold: 4/5\n",
      "training: dense_nn mc \n",
      "sequential: False\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_3 (Normalizat  (None, 37)               75        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 500)               19000     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                5010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 775,585\n",
      "Trainable params: 775,510\n",
      "Non-trainable params: 75\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "16721/16721 [==============================] - 360s 21ms/step - loss: 0.3884 - accuracy: 0.8577\n",
      "Epoch 2/50\n",
      "16721/16721 [==============================] - 361s 22ms/step - loss: 0.3639 - accuracy: 0.8618\n",
      "Epoch 3/50\n",
      "16721/16721 [==============================] - 366s 22ms/step - loss: 0.3585 - accuracy: 0.8626\n",
      "Epoch 4/50\n",
      "16721/16721 [==============================] - 376s 22ms/step - loss: 0.3572 - accuracy: 0.8630\n",
      "Epoch 5/50\n",
      "16721/16721 [==============================] - 374s 22ms/step - loss: 0.3538 - accuracy: 0.8633\n",
      "Epoch 6/50\n",
      "16721/16721 [==============================] - 370s 22ms/step - loss: 0.3521 - accuracy: 0.8636\n",
      "Epoch 7/50\n",
      "16721/16721 [==============================] - 364s 22ms/step - loss: 0.3511 - accuracy: 0.8639\n",
      "Epoch 8/50\n",
      "16721/16721 [==============================] - 356s 21ms/step - loss: 0.3501 - accuracy: 0.8640\n",
      "Epoch 9/50\n",
      "16721/16721 [==============================] - 356s 21ms/step - loss: 0.3493 - accuracy: 0.8640\n",
      "Epoch 10/50\n",
      "16721/16721 [==============================] - 355s 21ms/step - loss: 0.3487 - accuracy: 0.8641\n",
      "Epoch 11/50\n",
      "16721/16721 [==============================] - 357s 21ms/step - loss: 0.3486 - accuracy: 0.8641\n",
      "Epoch 12/50\n",
      "16721/16721 [==============================] - 354s 21ms/step - loss: 0.3569 - accuracy: 0.8642\n",
      "Epoch 13/50\n",
      "16721/16721 [==============================] - 357s 21ms/step - loss: 0.3466 - accuracy: 0.8643\n",
      "Epoch 14/50\n",
      "16721/16721 [==============================] - 358s 21ms/step - loss: 0.3477 - accuracy: 0.8644\n",
      "Epoch 15/50\n",
      "16721/16721 [==============================] - 360s 22ms/step - loss: 0.3459 - accuracy: 0.8644\n",
      "Epoch 16/50\n",
      "16721/16721 [==============================] - 359s 21ms/step - loss: 0.3463 - accuracy: 0.8644\n",
      "Epoch 17/50\n",
      "16721/16721 [==============================] - 359s 21ms/step - loss: 0.3496 - accuracy: 0.8644\n",
      "Epoch 18/50\n",
      "16721/16721 [==============================] - 358s 21ms/step - loss: 0.3455 - accuracy: 0.8644\n",
      "Epoch 19/50\n",
      "16721/16721 [==============================] - 361s 22ms/step - loss: 0.3456 - accuracy: 0.8644\n",
      "Epoch 20/50\n",
      "16721/16721 [==============================] - 362s 22ms/step - loss: 0.3570 - accuracy: 0.8645\n",
      "Epoch 21/50\n",
      "16721/16721 [==============================] - 362s 22ms/step - loss: 0.3460 - accuracy: 0.8644\n",
      "Epoch 22/50\n",
      "16721/16721 [==============================] - 362s 22ms/step - loss: 0.4367 - accuracy: 0.8644\n",
      "Epoch 23/50\n",
      "16721/16721 [==============================] - 357s 21ms/step - loss: 0.3448 - accuracy: 0.8644\n",
      "Epoch 24/50\n",
      "16721/16721 [==============================] - 360s 22ms/step - loss: 0.3458 - accuracy: 0.8645\n",
      "Epoch 25/50\n",
      "16721/16721 [==============================] - 360s 22ms/step - loss: 0.3449 - accuracy: 0.8646\n",
      "Epoch 26/50\n",
      "16721/16721 [==============================] - 360s 22ms/step - loss: 0.3497 - accuracy: 0.8644\n",
      "Epoch 27/50\n",
      "16721/16721 [==============================] - 360s 22ms/step - loss: 0.3442 - accuracy: 0.8645\n",
      "Epoch 28/50\n",
      "16721/16721 [==============================] - 359s 21ms/step - loss: 0.3460 - accuracy: 0.8645\n",
      "Epoch 29/50\n",
      "16721/16721 [==============================] - 363s 22ms/step - loss: 0.3521 - accuracy: 0.8645\n",
      "Epoch 30/50\n",
      "16721/16721 [==============================] - 363s 22ms/step - loss: 0.3446 - accuracy: 0.8644\n",
      "Epoch 31/50\n",
      "16721/16721 [==============================] - 363s 22ms/step - loss: 0.3439 - accuracy: 0.8645\n",
      "Epoch 32/50\n",
      "16721/16721 [==============================] - 364s 22ms/step - loss: 0.3437 - accuracy: 0.8646\n",
      "Epoch 33/50\n",
      "16721/16721 [==============================] - 367s 22ms/step - loss: 0.3445 - accuracy: 0.8646\n",
      "Epoch 34/50\n",
      "16721/16721 [==============================] - 379s 23ms/step - loss: 0.3442 - accuracy: 0.8646\n",
      "Epoch 35/50\n",
      "16721/16721 [==============================] - 379s 23ms/step - loss: 0.3454 - accuracy: 0.8645\n",
      "Epoch 36/50\n",
      "16721/16721 [==============================] - 380s 23ms/step - loss: 0.3429 - accuracy: 0.8646\n",
      "Epoch 37/50\n",
      "16721/16721 [==============================] - 381s 23ms/step - loss: 0.4223 - accuracy: 0.8647\n",
      "Epoch 38/50\n",
      "16721/16721 [==============================] - 378s 23ms/step - loss: 0.4381 - accuracy: 0.8647\n",
      "Epoch 39/50\n",
      "16721/16721 [==============================] - 376s 22ms/step - loss: 0.3426 - accuracy: 0.8646\n",
      "Epoch 40/50\n",
      "16721/16721 [==============================] - 377s 23ms/step - loss: 0.3432 - accuracy: 0.8644\n",
      "Epoch 41/50\n",
      "16721/16721 [==============================] - 378s 23ms/step - loss: 0.3451 - accuracy: 0.8640\n",
      "Epoch 42/50\n",
      "16721/16721 [==============================] - 379s 23ms/step - loss: 0.3549 - accuracy: 0.8646\n",
      "Epoch 43/50\n",
      "16721/16721 [==============================] - 377s 23ms/step - loss: 0.3430 - accuracy: 0.8646\n",
      "Epoch 44/50\n",
      "16721/16721 [==============================] - 373s 22ms/step - loss: 0.3431 - accuracy: 0.8646\n",
      "Epoch 45/50\n",
      "16721/16721 [==============================] - 379s 23ms/step - loss: 0.3453 - accuracy: 0.8647\n",
      "Epoch 46/50\n",
      "16721/16721 [==============================] - 378s 23ms/step - loss: 0.3539 - accuracy: 0.8645\n",
      "Epoch 47/50\n",
      "16721/16721 [==============================] - 379s 23ms/step - loss: 0.3435 - accuracy: 0.8645\n",
      "Epoch 48/50\n",
      "16721/16721 [==============================] - 379s 23ms/step - loss: 0.3453 - accuracy: 0.8644\n",
      "Epoch 49/50\n",
      "16721/16721 [==============================] - 367s 22ms/step - loss: 0.3444 - accuracy: 0.8644\n",
      "4181/4181 [==============================] - 35s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:\n",
      "[[495221   7413     44      0     87     24      1     22      0      0]\n",
      " [  6219 416926   1606     39   5071      0      0      0      0      0]\n",
      " [   795  64844   1773     19    609      0      0      2      0      0]\n",
      " [   100   6510    472     36    119      0      0      4      0      0]\n",
      " [  1097  49555    430      2   4453      0      0      2      0      0]\n",
      " [    85      0      0      0      0    935      0      0      0      0]\n",
      " [    56      0      0      0      0      8   5365      0      0      0]\n",
      " [    46      0      0      0      0      0      2     55      0      0]\n",
      " [     4      0      0      0      0      0      0     36      0      0]\n",
      " [     5      0      0      0      0      0      0     24      0      0]]\n",
      "End of confusion_matrix:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrateur\\Desktop\\GDLC\\src\\models\\model.py:88: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  class_precision[i] = tp / (tp + fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98    502812\n",
      "           1       0.76      0.97      0.86    429861\n",
      "           2       0.41      0.03      0.05     68042\n",
      "           3       0.38      0.00      0.01      7241\n",
      "           4       0.43      0.08      0.14     55539\n",
      "           5       0.97      0.92      0.94      1020\n",
      "           6       1.00      0.99      0.99      5429\n",
      "           7       0.38      0.53      0.44       103\n",
      "           8       0.00      0.00      0.00        40\n",
      "           9       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.86   1070116\n",
      "   macro avg       0.53      0.45      0.44   1070116\n",
      "weighted avg       0.83      0.86      0.82   1070116\n",
      "\n",
      "End of Classification Report:\n",
      "dense_nn mc : {'accuracy': 0.8641717346530656, 'recall': 0.8641717346530656, 'precision': 0.8261665603473413, 'f1s': 0.8220828133184445, 'FPR': 0.015092029482992706, 'FNR': 0.13582826534693435, 'time': 36.407933473587036, 'fold': 4}\n",
      "dense_nn mc  average accuracy: 0.8644974951738301\n",
      "==>> train_index: [      0       1       2 ... 5350579 5350580 5350582]\n",
      "==>> training_labels: (4280467,)\n",
      "==>> test_index: [      6       9      11 ... 5350574 5350576 5350581]\n",
      "==>> testing_labels: (1070116,)\n",
      "fold: 5\n",
      "=====================================\n",
      "=====================================\n",
      "fold: 5/5\n",
      "training: dense_nn mc \n",
      "sequential: False\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_4 (Normalizat  (None, 37)               75        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 500)               19000     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 10)                5010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 775,585\n",
      "Trainable params: 775,510\n",
      "Non-trainable params: 75\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "16721/16721 [==============================] - 363s 22ms/step - loss: 0.3881 - accuracy: 0.8578\n",
      "Epoch 2/50\n",
      "16721/16721 [==============================] - 366s 22ms/step - loss: 0.3637 - accuracy: 0.8618\n",
      "Epoch 3/50\n",
      "16721/16721 [==============================] - 367s 22ms/step - loss: 0.3586 - accuracy: 0.8625\n",
      "Epoch 4/50\n",
      "16721/16721 [==============================] - 369s 22ms/step - loss: 0.3553 - accuracy: 0.8631\n",
      "Epoch 5/50\n",
      "16721/16721 [==============================] - 368s 22ms/step - loss: 0.3537 - accuracy: 0.8634\n",
      "Epoch 6/50\n",
      "16721/16721 [==============================] - 370s 22ms/step - loss: 0.3522 - accuracy: 0.8636\n",
      "Epoch 7/50\n",
      "16721/16721 [==============================] - 378s 23ms/step - loss: 0.3517 - accuracy: 0.8637\n",
      "Epoch 8/50\n",
      "16721/16721 [==============================] - 380s 23ms/step - loss: 0.3499 - accuracy: 0.8639\n",
      "Epoch 9/50\n",
      "16721/16721 [==============================] - 379s 23ms/step - loss: 0.3496 - accuracy: 0.8640\n",
      "Epoch 10/50\n",
      "16721/16721 [==============================] - 380s 23ms/step - loss: 0.3526 - accuracy: 0.8640\n",
      "Epoch 11/50\n",
      "16721/16721 [==============================] - 370s 22ms/step - loss: 0.3478 - accuracy: 0.8642\n",
      "Epoch 12/50\n",
      "16721/16721 [==============================] - 373s 22ms/step - loss: 0.3481 - accuracy: 0.8642\n",
      "Epoch 13/50\n",
      "16721/16721 [==============================] - 372s 22ms/step - loss: 0.3479 - accuracy: 0.8642\n",
      "Epoch 14/50\n",
      "16721/16721 [==============================] - 369s 22ms/step - loss: 0.3464 - accuracy: 0.8643\n",
      "Epoch 15/50\n",
      "16721/16721 [==============================] - 371s 22ms/step - loss: 0.3461 - accuracy: 0.8643\n",
      "Epoch 16/50\n",
      "16721/16721 [==============================] - 370s 22ms/step - loss: 0.3459 - accuracy: 0.8643\n",
      "Epoch 17/50\n",
      "16721/16721 [==============================] - 375s 22ms/step - loss: 0.3461 - accuracy: 0.8644\n",
      "Epoch 18/50\n",
      "16721/16721 [==============================] - 376s 22ms/step - loss: 0.3455 - accuracy: 0.8644\n",
      "Epoch 19/50\n",
      "16721/16721 [==============================] - 372s 22ms/step - loss: 0.3448 - accuracy: 0.8644\n",
      "Epoch 20/50\n",
      "16721/16721 [==============================] - 367s 22ms/step - loss: 0.3475 - accuracy: 0.8645\n",
      "Epoch 21/50\n",
      "16721/16721 [==============================] - 382s 23ms/step - loss: 0.3470 - accuracy: 0.8644\n",
      "Epoch 22/50\n",
      "16721/16721 [==============================] - 370s 22ms/step - loss: 0.3461 - accuracy: 0.8644\n",
      "Epoch 23/50\n",
      "16721/16721 [==============================] - 370s 22ms/step - loss: 0.3500 - accuracy: 0.8644\n",
      "Epoch 24/50\n",
      "16721/16721 [==============================] - 367s 22ms/step - loss: 0.3445 - accuracy: 0.8645\n",
      "Epoch 25/50\n",
      "16721/16721 [==============================] - 367s 22ms/step - loss: 0.3935 - accuracy: 0.8646\n",
      "Epoch 26/50\n",
      "16721/16721 [==============================] - 375s 22ms/step - loss: 0.3439 - accuracy: 0.8645\n",
      "Epoch 27/50\n",
      "16721/16721 [==============================] - 374s 22ms/step - loss: 0.3832 - accuracy: 0.8644\n",
      "Epoch 28/50\n",
      "16721/16721 [==============================] - 373s 22ms/step - loss: 0.3467 - accuracy: 0.8645\n",
      "Epoch 29/50\n",
      "16721/16721 [==============================] - 369s 22ms/step - loss: 0.3550 - accuracy: 0.8642\n",
      "Epoch 30/50\n",
      "16721/16721 [==============================] - 377s 23ms/step - loss: 0.3448 - accuracy: 0.8645\n",
      "Epoch 31/50\n",
      "16721/16721 [==============================] - 383s 23ms/step - loss: 0.3507 - accuracy: 0.8644\n",
      "Epoch 32/50\n",
      "16721/16721 [==============================] - 385s 23ms/step - loss: 0.3525 - accuracy: 0.8645\n",
      "Epoch 33/50\n",
      "16721/16721 [==============================] - 386s 23ms/step - loss: 0.3447 - accuracy: 0.8643\n",
      "Epoch 34/50\n",
      "16721/16721 [==============================] - 384s 23ms/step - loss: 0.3448 - accuracy: 0.8643\n",
      "Epoch 35/50\n",
      "16721/16721 [==============================] - 373s 22ms/step - loss: 0.3522 - accuracy: 0.8646\n",
      "Epoch 36/50\n",
      "16721/16721 [==============================] - 378s 23ms/step - loss: 0.3447 - accuracy: 0.8645\n",
      "4181/4181 [==============================] - 37s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:\n",
      "[[495462   7229     31      2     80      5      2      0      0      0]\n",
      " [  6628 417081   2956    161   3036      0      0      0      0      0]\n",
      " [   905  64131   2710     85    211      0      0      0      0      0]\n",
      " [   139   6269    725     54     54      0      0      0      0      0]\n",
      " [  1280  50876    383      1   2999      0      0      0      0      0]\n",
      " [   167      0      0      0      0    852      0      0      0      0]\n",
      " [    52      0      0      0      0      3   5374      0      0      0]\n",
      " [   104      0      0      0      0      0      0      0      0      0]\n",
      " [    40      0      0      0      0      0      0      0      0      0]\n",
      " [    29      0      0      0      0      0      0      0      0      0]]\n",
      "End of confusion_matrix:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    502811\n",
      "           1       0.76      0.97      0.86    429862\n",
      "           2       0.40      0.04      0.07     68042\n",
      "           3       0.18      0.01      0.01      7241\n",
      "           4       0.47      0.05      0.10     55539\n",
      "           5       0.99      0.84      0.91      1019\n",
      "           6       1.00      0.99      0.99      5429\n",
      "           7       0.00      0.00      0.00       104\n",
      "           8       0.00      0.00      0.00        40\n",
      "           9       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.86   1070116\n",
      "   macro avg       0.48      0.39      0.39   1070116\n",
      "weighted avg       0.83      0.86      0.82   1070116\n",
      "\n",
      "End of Classification Report:\n",
      "dense_nn mc : {'accuracy': 0.8639549357265941, 'recall': 0.8639549357265941, 'precision': 0.8251896689222412, 'f1s': 0.8212345204461979, 'FPR': 0.015116118252600654, 'FNR': 0.13604506427340587, 'time': 38.0209846496582, 'fold': 5}\n",
      "dense_nn mc  average accuracy: 0.864388983284383\n",
      "==>> results: {'configuration': 'stratified k-fold cross validation - manual sequences', 'multi_class': True, 'with_sort_timestamp': True, 'sequence_length': 3, 'with_cross_validation': True, 'cross_validation_splits_num': 5, 'with_network_features': False, 'network_features': ['betweenness', 'local_betweenness', 'degree', 'local_degree', 'closeness', 'pagerank', 'local_pagerank', 'k_truss', 'Comm'], 'dataset_name': 'cic_ton_iot', 'input_dim': 37, 'dropped_columns': ['Flow ID', 'Src IP', 'Dst IP', 'Timestamp', 'Src Port', 'Dst Port', 'Attack'], 'num_dropped_columns': 7, 'models': {'dense_nn mc ': {'scores': [{'accuracy': 0.8644998630990817, 'recall': 0.8644998630990817, 'precision': 0.8256241834073993, 'f1s': 0.8176462859703906, 'FPR': 0.015055570766768701, 'FNR': 0.1355001369009183, 'time': 35.24499297142029, 'fold': 1}, {'accuracy': 0.8649035572745783, 'recall': 0.8649035572745783, 'precision': 0.829086623842031, 'f1s': 0.8191775395802355, 'FPR': 0.015010715858380179, 'FNR': 0.13509644272542162, 'time': 35.07294678688049, 'fold': 2}, {'accuracy': 0.8644148256685951, 'recall': 0.8644148256685951, 'precision': 0.8251424636197394, 'f1s': 0.8220949541629533, 'FPR': 0.015065019370156097, 'FNR': 0.13558517433140488, 'time': 36.44901132583618, 'fold': 3}, {'accuracy': 0.8641717346530656, 'recall': 0.8641717346530656, 'precision': 0.8261665603473413, 'f1s': 0.8220828133184445, 'FPR': 0.015092029482992706, 'FNR': 0.13582826534693435, 'time': 36.407933473587036, 'fold': 4}, {'accuracy': 0.8639549357265941, 'recall': 0.8639549357265941, 'precision': 0.8251896689222412, 'f1s': 0.8212345204461979, 'FPR': 0.015116118252600654, 'FNR': 0.13604506427340587, 'time': 38.0209846496582, 'fold': 5}], 'class_report': [{'records_count': {0: 502812, 1: 429862, 2: 68041, 3: 7241, 4: 55540, 5: 1019, 6: 5429, 7: 104, 8: 40, 9: 29}, 'class_accuracy': {0: 0.9848175479877433, 1: 0.8678237987061228, 2: 0.935970552752643, 3: 0.9931642988570408, 4: 0.9477926245447927, 5: 0.9997131154817651, 6: 0.9998691731838668, 7: 0.9999130936149973, 8: 0.9999626209096762, 9: 0.9999729001595152}, 'class_precision': {0: 0.9835486236854502, 1: 0.7606805470696056, 2: 0.4114814814814815, 3: 0.27710843373493976, 4: 0.46264236902050115, 5: 0.8588709677419355, 6: 0.9863895530623505, 7: 0.5495495495495496, 8: nan, 9: nan}, 'class_recall': {0: 0.9841491452073539, 1: 0.9789420790858462, 2: 0.016328390235299306, 3: 0.006352713713575473, 4: 0.036568239106949944, 5: 0.8361138370951914, 6: 0.9878430650211826, 7: 0.5865384615384616, 8: 0.0, 9: 0.0}, 'class_f1': {0: 0.8446149204282691, 1: 0.8446149204282691, 2: 0.8446149204282691, 3: 0.8446149204282691, 4: 0.8446149204282691, 5: 0.8446149204282691, 6: 0.8446149204282691, 7: 0.8446149204282691, 8: 0.8446149204282691, 9: 0.8446149204282691}, 'class_fnr': {0: 0.015850854792646158, 1: 0.021057920914153844, 2: 0.9836716097647007, 3: 0.9936472862864245, 4: 0.96343176089305, 5: 0.16388616290480865, 6: 0.012156934978817462, 7: 0.41346153846153844, 8: 1.0, 9: 1.0}, 'class_fpr': {0: 0.014590035342540608, 1: 0.20678011104950372, 2: 0.0015857080700465832, 3: 0.00011290122272024207, 4: 0.002325106916478493, 5: 0.00013095151239643138, 6: 6.950392978976001e-05, 7: 4.672840423434108e-05, 8: 0.0, 9: 0.0}}, {'records_count': {0: 502812, 1: 429862, 2: 68041, 3: 7241, 4: 55539, 5: 1020, 6: 5429, 7: 103, 8: 41, 9: 29}, 'class_accuracy': {0: 0.9853165588435657, 1: 0.867527569415307, 2: 0.9361340862728095, 3: 0.9932259743560751, 4: 0.9479486822468945, 5: 0.9998598284112858, 6: 0.9999327176374172, 7: 0.9999271107738686, 8: 0.9999616864324181, 9: 0.9999729001595152}, 'class_precision': {0: 0.9835564653349561, 1: 0.761195274748189, 2: 0.4395692062225768, 3: 0.2777777777777778, 4: 0.4867690297288468, 5: 0.9844097995545658, 6: 1.0, 7: 0.7659574468085106, 8: nan, 9: nan}, 'class_recall': {0: 0.9852211164411351, 1: 0.976599466805626, 2: 0.01619611704707456, 3: 0.0006905123601712471, 4: 0.05365598948486649, 5: 0.8666666666666667, 6: 0.9867378891140173, 7: 0.34951456310679613, 8: 0.0, 9: 0.0}, 'class_f1': {0: 0.8466164423421545, 1: 0.8466164423421545, 2: 0.8466164423421545, 3: 0.8466164423421545, 4: 0.8466164423421545, 5: 0.8466164423421545, 6: 0.8466164423421545, 7: 0.8466164423421545, 8: 0.8466164423421545, 9: 0.8466164423421545}, 'class_fnr': {0: 0.014778883558864944, 1: 0.023400533194374008, 2: 0.9838038829529254, 3: 0.9993094876398287, 4: 0.9463440105151335, 5: 0.13333333333333333, 6: 0.013262110885982685, 7: 0.6504854368932039, 8: 1.0, 9: 1.0}, 'class_fpr': {0: 0.014598848943689902, 1: 0.2057024154438466, 2: 0.0014020892626906542, 3: 1.223096579469289e-05, 4: 0.0030968540614915757, 5: 1.309516348843931e-05, 6: 0.0, 7: 1.0280239323971463e-05, 8: 0.0, 9: 0.0}}, {'records_count': {0: 502812, 1: 429861, 2: 68042, 3: 7241, 4: 55539, 5: 1020, 6: 5429, 7: 103, 8: 41, 9: 29}, 'class_accuracy': {0: 0.9849988365758137, 1: 0.8689816160289016, 2: 0.9343651208232371, 3: 0.9932063503336551, 4: 0.9476412392289815, 5: 0.999881321388222, 6: 0.999920569433062, 7: 0.9999317831601591, 8: 0.9999317831601591, 9: 0.9999710312049991}, 'class_precision': {0: 0.9824411516923535, 1: 0.7658701893775288, 2: 0.38501833420639076, 3: 0.2898550724637681, 4: 0.44957896898747174, 5: 0.9724867724867725, 6: 0.9996260284218399, 7: 0.96875, 8: 0.34, 9: 0.0}, 'class_recall': {0: 0.985690476758709, 1: 0.9705323348710397, 2: 0.0540107580611975, 3: 0.0027620494406849884, 4: 0.039413745296098236, 5: 0.9009803921568628, 6: 0.9847117332842144, 7: 0.30097087378640774, 8: 0.8292682926829268, 9: 0.0}, 'class_f1': {0: 0.844322217853944, 1: 0.844322217853944, 2: 0.844322217853944, 3: 0.844322217853944, 4: 0.844322217853944, 5: 0.844322217853944, 6: 0.844322217853944, 7: 0.844322217853944, 8: 0.844322217853944, 9: 0.844322217853944}, 'class_fnr': {0: 0.01430952324129098, 1: 0.02946766512896029, 2: 0.9459892419388025, 3: 0.997237950559315, 4: 0.9605862547039018, 5: 0.09901960784313725, 6: 0.015288266715785596, 7: 0.6990291262135923, 8: 0.17073170731707318, 9: 1.0}, 'class_fpr': {0: 0.015614175796088524, 1: 0.1991984456217513, 2: 0.005857844971683756, 3: 4.6101332610765507e-05, 4: 0.002641492324887786, 5: 2.4319589335673004e-05, 6: 1.8784845889124325e-06, 7: 9.345672112701329e-07, 8: 6.16778621331569e-05, 9: 1.8690051659302787e-06}}, {'records_count': {0: 502812, 1: 429861, 2: 68042, 3: 7241, 4: 55539, 5: 1020, 6: 5429, 7: 103, 8: 40, 9: 29}, 'class_accuracy': {0: 0.9850502188547784, 1: 0.8679984226009143, 2: 0.9356882805228592, 3: 0.9932110163757948, 4: 0.9467609119011396, 5: 0.9998906660586329, 6: 0.9999373899652, 7: 0.9998710420178747, 8: 0.9999626208747463, 9: 0.999972900134191}, 'class_precision': {0: 0.9833071235117984, 1: 0.7646538822700862, 2: 0.4099421965317919, 3: 0.375, 4: 0.4306992939355837, 5: 0.9669079627714581, 6: 0.999441132637854, 7: 0.3793103448275862, 8: nan, 9: nan}, 'class_recall': {0: 0.9849029060563391, 1: 0.9699088775208731, 2: 0.026057435113606302, 3: 0.004971688993232979, 4: 0.08017789301211761, 5: 0.9166666666666666, 6: 0.9882114569902376, 7: 0.5339805825242718, 8: 0.0, 9: 0.0}, 'class_f1': {0: 0.8447418977365672, 1: 0.8447418977365672, 2: 0.8447418977365672, 3: 0.8447418977365672, 4: 0.8447418977365672, 5: 0.8447418977365672, 6: 0.8447418977365672, 7: 0.8447418977365672, 8: 0.8447418977365672, 9: 0.8447418977365672}, 'class_fnr': {0: 0.015097093943660852, 1: 0.030091122479126972, 2: 0.9739425648863937, 3: 0.995028311006767, 4: 0.9198221069878824, 5: 0.08333333333333333, 6: 0.011788543009762387, 7: 0.46601941747572817, 8: 1.0, 9: 1.0}, 'class_fpr': {0: 0.01481921509455248, 1: 0.20042326885381606, 2: 0.0025467181066468145, 3: 5.645066447136305e-05, 4: 0.005801432518182454, 5: 2.9931830256590616e-05, 6: 2.817729529899398e-06, 7: 8.411112762181394e-05, 8: 0.0, 9: 0.0}}, {'records_count': {0: 502811, 1: 429862, 2: 68042, 3: 7241, 4: 55539, 5: 1019, 6: 5429, 7: 104, 8: 40, 9: 29}, 'class_accuracy': {0: 0.9844007565534951, 1: 0.8679713227351054, 2: 0.9351219867752655, 3: 0.9930512206153351, 4: 0.9477430484171809, 5: 0.9998364663270151, 6: 0.9999467347465134, 7: 0.9999028142743404, 8: 0.9999626208747463, 9: 0.999972900134191}, 'class_precision': {0: 0.9814899188995376, 1: 0.7644642641123489, 2: 0.3982365907421014, 3: 0.1782178217821782, 4: 0.4700626959247649, 5: 0.9906976744186047, 6: 0.9996279761904762, 7: nan, 8: nan, 9: nan}, 'class_recall': {0: 0.9853841701951628, 1: 0.9702672020322801, 2: 0.03982834131859734, 3: 0.007457533489849468, 4: 0.05399809143124651, 5: 0.8361138370951914, 6: 0.9898692208509855, 7: 0.0, 8: 0.0, 9: 0.0}, 'class_f1': {0: 0.8441274777942156, 1: 0.8441274777942156, 2: 0.8441274777942156, 3: 0.8441274777942156, 4: 0.8441274777942156, 5: 0.8441274777942156, 6: 0.8441274777942156, 7: 0.8441274777942156, 8: 0.8441274777942156, 9: 0.8441274777942156}, 'class_fnr': {0: 0.014615829804837206, 1: 0.02973279796771987, 2: 0.9601716586814026, 3: 0.9925424665101505, 4: 0.9460019085687534, 5: 0.16388616290480865, 6: 0.010130779149014552, 7: 1.0, 8: 1.0, 9: 1.0}, 'class_fpr': {0: 0.016470857827799862, 1: 0.2007094059545118, 2: 0.004086524548087267, 3: 0.00023427025755615665, 4: 0.003332423266050778, 5: 7.482950564822462e-06, 6: 1.878486353266265e-06, 7: 0.0, 8: 0.0, 9: 0.0}}], 'average': [{'average_acc': 0.8644998630990817, 'average_recall': 0.8644998630990817, 'average_precision': 0.8256241834073993, 'average_f1s': 0.8176462859703906, 'average_FPR': 0.015055570766768701, 'average_FNR': 0.1355001369009183, 'fold': 1}, {'average_acc': 0.86470171018683, 'average_recall': 0.86470171018683, 'average_precision': 0.8273554036247152, 'average_f1s': 0.8184119127753131, 'average_FPR': 0.01503314331257444, 'average_FNR': 0.13529828981316996, 'fold': 2}, {'average_acc': 0.864606082014085, 'average_recall': 0.864606082014085, 'average_precision': 0.8266177569563898, 'average_f1s': 0.8196395932378598, 'average_FPR': 0.01504376866510166, 'average_FNR': 0.13539391798591494, 'fold': 3}, {'average_acc': 0.8644974951738301, 'average_recall': 0.8644974951738301, 'average_precision': 0.8265049578041277, 'average_f1s': 0.820250398258006, 'average_FPR': 0.015055833869574422, 'average_FNR': 0.1355025048261698, 'fold': 4}, {'average_acc': 0.864388983284383, 'average_recall': 0.864388983284383, 'average_precision': 0.8262419000277503, 'average_f1s': 0.8204472226956444, 'average_FPR': 0.015067890746179669, 'average_FNR': 0.135611016715617, 'fold': 5}]}}, 'average_acc': {'dense_nn mc ': 0.864388983284383}, 'average': {'dense_nn mc ': {'average_acc': 0.864388983284383, 'average_recall': 0.864388983284383, 'average_precision': 0.8262419000277503, 'average_f1s': 0.8204472226956444, 'average_FPR': 0.015067890746179669, 'average_FNR': 0.135611016715617}}, 'endtime': '2024:02:20-10:01:06'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrateur\\Desktop\\GDLC\\src\\models\\model.py:88: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  class_precision[i] = tp / (tp + fp)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=cross_validation_splits_num, shuffle=True, random_state=24)\n",
    "i = 0\n",
    "for train_index, test_index in skf.split(df, labels):\n",
    "    training_labels = labels[train_index]\n",
    "    print(f\"==>> train_index: {train_index}\")\n",
    "    print(f\"==>> training_labels: {training_labels.shape}\")\n",
    "    testing_labels = labels[test_index]\n",
    "    print(f\"==>> test_index: {test_index}\")\n",
    "    print(f\"==>> testing_labels: {testing_labels.shape}\")\n",
    "\n",
    "    i += 1\n",
    "    print(\"fold: {}\".format(i))\n",
    "    # print(\"train_index: {}\".format(train_index))\n",
    "    print(\"=====================================\")\n",
    "    print(\"=====================================\")\n",
    "    # print(\"fold: {}/{}\".format(i, len(list_of_dfs)))\n",
    "    print(\"fold: {}/{}\".format(i, cross_validation_splits_num))\n",
    "\n",
    "    for model in models:\n",
    "        print(\"training: {}\".format(model.model_name()))\n",
    "        print(\"sequential: {}\".format(model.sequential))\n",
    "\n",
    "        if model.sequential:\n",
    "            training = df[train_index]\n",
    "            testing = df[test_index]\n",
    "        else:\n",
    "            training = df_non_seq[train_index]\n",
    "            testing = df_non_seq[test_index]\n",
    "            \n",
    "            # scaler = MinMaxScaler()\n",
    "            # training = scaler.fit_transform(training)\n",
    "            # testing = scaler.transform(testing)\n",
    "\n",
    "        model.build()\n",
    "        model.train(training,\n",
    "                    training_labels)  # type: ignore\n",
    "        predictions, prediction_time = model.predict(\n",
    "            testing)  # type: ignore\n",
    "        model_name, scores, class_report = model.evaluate(  # type: ignore\n",
    "            predictions,\n",
    "            testing_labels,\n",
    "            prediction_time\n",
    "        )\n",
    "        scores[\"fold\"] = i\n",
    "        if i == 1:\n",
    "            results[\"models\"][model_name] = {}\n",
    "            results[\"models\"][model_name][\"scores\"] = [scores]\n",
    "            results[\"models\"][model_name][\"class_report\"] = [class_report]\n",
    "        else:\n",
    "            results[\"models\"][model_name][\"scores\"].append(scores)\n",
    "            results[\"models\"][model_name][\"class_report\"].append(\n",
    "                class_report)\n",
    "        # results[str(i) + model_name] = scores\n",
    "        print(\"{}: {}\".format(model_name, scores))\n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.model_name()\n",
    "        average_acc = 0\n",
    "        average_recall = 0\n",
    "        average_precision = 0\n",
    "        average_f1s = 0\n",
    "        average_FPR = 0\n",
    "        average_FNR = 0\n",
    "        for result in results[\"models\"][model_name][\"scores\"]:  # type: ignore\n",
    "            average_acc += result[\"accuracy\"]\n",
    "            average_recall += result[\"recall\"]\n",
    "            average_precision += result[\"precision\"]\n",
    "            average_f1s += result[\"f1s\"]\n",
    "            average_FPR += result[\"FPR\"]\n",
    "            average_FNR += result[\"FNR\"]\n",
    "        average_acc = average_acc / i\n",
    "        average_recall = average_recall / i\n",
    "        average_precision = average_precision / i\n",
    "        average_f1s = average_f1s / i\n",
    "        average_FPR = average_FPR / i\n",
    "        average_FNR = average_FNR / i\n",
    "        if i == 1:\n",
    "            results[\"models\"][model_name][\"average\"] = [\n",
    "                {\n",
    "                    \"average_acc\": average_acc,\n",
    "                    \"average_recall\": average_recall,\n",
    "                    \"average_precision\": average_precision,\n",
    "                    \"average_f1s\": average_f1s,\n",
    "                    \"average_FPR\": average_FPR,\n",
    "                    \"average_FNR\": average_FNR,\n",
    "                    \"fold\": i\n",
    "                }\n",
    "            ]\n",
    "            results[\"average_acc\"][model_name] = average_acc\n",
    "            results[\"average\"][model_name] = {\n",
    "                \"average_acc\": average_acc,\n",
    "                \"average_recall\": average_recall,\n",
    "                \"average_precision\": average_precision,\n",
    "                \"average_f1s\": average_f1s,\n",
    "                \"average_FPR\": average_FPR,\n",
    "                \"average_FNR\": average_FNR\n",
    "            }\n",
    "        else:\n",
    "            results[\"models\"][model_name][\"average\"].append(\n",
    "                {\n",
    "                    \"average_acc\": average_acc,\n",
    "                    \"average_recall\": average_recall,\n",
    "                    \"average_precision\": average_precision,\n",
    "                    \"average_f1s\": average_f1s,\n",
    "                    \"average_FPR\": average_FPR,\n",
    "                    \"average_FNR\": average_FNR,\n",
    "                    \"fold\": i\n",
    "                })\n",
    "            results[\"average_acc\"][model_name] = average_acc\n",
    "            results[\"average\"][model_name] = {\n",
    "                \"average_acc\": average_acc,\n",
    "                \"average_recall\": average_recall,\n",
    "                \"average_precision\": average_precision,\n",
    "                \"average_f1s\": average_f1s,\n",
    "                \"average_FPR\": average_FPR,\n",
    "                \"average_FNR\": average_FNR\n",
    "            }\n",
    "        print(\"{} average accuracy: {}\".format(model_name, average_acc))\n",
    "\n",
    "results[\"endtime\"] = time.strftime(\"%Y:%m:%d-%H:%M:%S\")\n",
    "\n",
    "print(f\"==>> results: {results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the directories if they don't exist\n",
    "if not os.path.isdir('./results'):\n",
    "    os.mkdir('./results')\n",
    "\n",
    "if not os.path.isdir('./results/{}'.format(dataset_name)):\n",
    "    os.mkdir('./results/{}'.format(dataset_name))\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NumpyEncoder, self).default(obj)\n",
    "\n",
    "# saving the results to a file for future refernece\n",
    "filename = ('./results/{}/{}.json'.format(dataset_name,\n",
    "            time.strftime(\"%Y%m%d-%H%M%S\")))\n",
    "outfile = open(filename, 'w')\n",
    "outfile.writelines(json.dumps(results, cls=NumpyEncoder))\n",
    "outfile.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
