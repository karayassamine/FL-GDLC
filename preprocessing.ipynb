{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing file for data cleaning and transformation before analysis.\n",
    "This notebook includes code for:\n",
    "1. Data loading and cleaning\n",
    "2. Graph Construction\n",
    "3. Complex Networks Measures Computation\n",
    "4. Adding Complex Networks Features to the dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# datasets is a list of available datasets descriptions containing: path, key columns names, and suitable complex network features\n",
    "from src.data.dataset_info import datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets[0]\n",
    "name = dataset.name\n",
    "print(\"dataset: {}\".format(name))\n",
    "\n",
    "path = \"./datasets/original/{}.pkl\".format(name)\n",
    "new_path = \"./datasets/preprocessed/{}.pkl\".format(name)\n",
    "graph_path = \"./datasets/preprocessed/graph_{}.gexf\".format(name)\n",
    "df = pd.read_pickle(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping infinity values, Nan values, and duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting all infinity values into nan then dropping all records containing nan values\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "df.drop_duplicates(subset=list(set(df.columns) - set([dataset.timestamp_col, dataset.flow_id_col])), keep=\"first\", inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Properties\n",
    "\n",
    "calculating main dataset properties and saving them in a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = len(df)\n",
    "\n",
    "properties = {\n",
    "    \"name\": dataset.name,\n",
    "    \"length\": total_count,\n",
    "}\n",
    "\n",
    "num_benign = len(df[df['Label'] == 0])\n",
    "num_attack = len(df[df['Label'] == 1])\n",
    "\n",
    "properties[\"num_benign\"] = num_benign\n",
    "properties[\"percentage_of_benign_records\"] = ((num_benign * 100)/total_count)\n",
    "\n",
    "properties[\"num_attack\"] = num_attack\n",
    "properties[\"percentage_of_attack_records\"] = ((num_attack * 100)/total_count)\n",
    "\n",
    "properties[\"attacks\"] = list(df[\"Attack\"].unique())  # .to_list()\n",
    "\n",
    "filename = ('./datasets_properties/{}.json'.format(dataset.name))\n",
    "outfile = open(filename, 'w')\n",
    "outfile.writelines(json.dumps(properties))\n",
    "outfile.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Graph Construction\n",
    "\n",
    "Graph construction from the records in the dataset.<br>\n",
    "Nodes are specified by IP addresses. <br>\n",
    "If there exists atleast one network flow between two different IP addresses, an edge will be created. <br>\n",
    "Another way can be considered is to use MultiDiGraph class. However, some centralities will not work in addition to transitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(\n",
    "        df,\n",
    "        source=dataset.src_ip_col,\n",
    "        target=dataset.dst_ip_col,\n",
    "        create_using=nx.DiGraph()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.remove_nodes_from(list(nx.isolates(G)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying the communities in the graph using the methods get_communities. <br>\n",
    "Since communities can be calculated using different methods, and we want to use get communites at different stages of the code, we implemented it in a separate file, so a change will be done one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "G1 = ig.Graph.from_networkx(G)\n",
    "part = G1.community_infomap()\n",
    "\n",
    "communities = []\n",
    "for com in part:\n",
    "    communities.append([G1.vs[node_index]['label'] for node_index in com])\n",
    "\n",
    "print(f\"==>> number of communities: {len(communities)}\")\n",
    "for com in communities:\n",
    "    print(f\"==>> com: {len(com)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Complex Networks Measures Computation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Computing Graph-level Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = {}\n",
    "\n",
    "properties[\"number_of_nodes\"] = G.number_of_nodes()\n",
    "properties[\"number_of_edges\"] = G.number_of_edges()\n",
    "\n",
    "degrees = [degree for _, degree in G.degree()]\n",
    "properties[\"max_degree\"] = max(degrees)\n",
    "properties[\"avg_degree\"] = sum(degrees) / len(degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties[\"transitivity\"] = nx.transitivity(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties[\"density\"] =  nx.density(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming G is your graph and communities is a list of sets, where each set contains the nodes in a community\n",
    "\n",
    "# Step 1: Map each node to its community\n",
    "node_to_community = {}\n",
    "for community_index, community in enumerate(communities):\n",
    "    for node in community:\n",
    "        node_to_community[node] = community_index\n",
    "\n",
    "# Step 2: Count inter-cluster edges efficiently\n",
    "inter_cluster_edges = 0\n",
    "for u, v in G.edges():\n",
    "    # Directly check if u and v belong to different communities\n",
    "    if node_to_community[u] != node_to_community[v]:\n",
    "        inter_cluster_edges += 1\n",
    "\n",
    "\n",
    "properties[\"mixing_parameter\"] = inter_cluster_edges / G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties[\"modularity\"] = nx.community.modularity(G, communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = ('./datasets_properties/{}.json'.format(\"graph_\" + name))\n",
    "outfile = open(filename, 'w')\n",
    "outfile.writelines(json.dumps(properties))\n",
    "outfile.close()\n",
    "\n",
    "properties"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the graph-level metrics, suitable complex networks should be specified and added to the corresponding dataset in the list in src.data.dataset_info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Computing Node-level Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_labels = {}\n",
    "for i, community in enumerate(communities):\n",
    "    for node in community:\n",
    "        community_labels[node] = i\n",
    "\n",
    "nx.set_node_attributes(G, community_labels, \"new_community\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting inter and itra graph, to calculate the local and global variations of each centrality\n",
    "from src.network.network_features import separate_graph\n",
    "\n",
    "intra_graph, inter_graph = separate_graph(G, communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.network.network_features import cal_betweenness_centrality\n",
    "\n",
    "if \"betweenness\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, cal_betweenness_centrality(G), \"betweenness\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"local_betweenness\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, cal_betweenness_centrality(intra_graph), \"local_betweenness\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"global_betweenness\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, cal_betweenness_centrality(inter_graph), \"global_betweenness\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"degree\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.degree_centrality(G), \"degree\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"local_degree\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.degree_centrality(intra_graph), \"local_degree\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"global_degree\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.degree_centrality(inter_graph), \"global_degree\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"eigenvector\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.eigenvector_centrality(G, max_iter=600), \"eigenvector\")\n",
    "    print(\"calculated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"local_eigenvector\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.eigenvector_centrality(intra_graph), \"local_eigenvector\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"global_eigenvector\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.eigenvector_centrality(inter_graph), \"global_eigenvector\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"closeness\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.closeness_centrality(G), \"closeness\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"local_closeness\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.closeness_centrality(intra_graph), \"local_closeness\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"global_closeness\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.closeness_centrality(inter_graph), \"global_closeness\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"pagerank\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.pagerank(G, alpha=0.85), \"pagerank\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"local_pagerank\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.pagerank(intra_graph, alpha=0.85), \"local_pagerank\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"global_pagerank\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.pagerank(inter_graph, alpha=0.85), \"global_pagerank\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.network.network_features import cal_k_core\n",
    "\n",
    "if \"k_core\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, cal_k_core(G), \"k_core\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.network.network_features import cal_k_truss\n",
    "if \"k_truss\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, cal_k_truss(G), \"k_truss\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.network.CommCentralityCode import comm_centreality\n",
    "\n",
    "if \"Comm\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, comm_centreality(G, community_labels), \"Comm\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.network.modularity_vitality import modularity_vitality\n",
    "\n",
    "if \"mv\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, modularity_vitality(G, part), \"mv\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G, graph_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Adding Complex Networks Features to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dicts = {}\n",
    "for measure in dataset.cn_measures:\n",
    "    features_dicts[measure] = nx.get_node_attributes(G, measure)\n",
    "    print(f\"==>> features_dicts: {measure , len(features_dicts[measure])}\")\n",
    "    \n",
    "for feature in dataset.network_features:\n",
    "        if feature[:3] == \"src\":\n",
    "            df[feature] = df.apply(\n",
    "                lambda row: features_dicts[feature[4:]].get(row[dataset.src_ip_col], -1), axis=1)\n",
    "        if feature[:3] == \"dst\":\n",
    "            df[feature] = df.apply(\n",
    "                lambda row: features_dicts[feature[4:]].get(row[dataset.dst_ip_col], -1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(df, new_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
