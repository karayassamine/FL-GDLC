{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing file for data cleaning and transformation before analysis.\n",
    "This notebook includes code for:\n",
    "1. Data loading and cleaning\n",
    "2. Graph Construction\n",
    "3. Complex Networks Measures Computation\n",
    "4. Adding Complex Networks Features to the dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# datasets is a list of available datasets descriptions containing: path, key columns names, and suitable complex network features\n",
    "from src.data.dataset_info import datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: cic_ton_iot\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets[0]\n",
    "name = dataset.name\n",
    "print(\"dataset: {}\".format(name))\n",
    "\n",
    "path = \"./datasets/original/{}.pkl\".format(name)\n",
    "new_path = \"./datasets/preprocessed/{}.pkl\".format(name)\n",
    "graph_path = \"./datasets/preprocessed/graph_{}.gexf\".format(name)\n",
    "df = pd.read_pickle(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping infinity values, Nan values, and duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting all infinity values into nan then dropping all records containing nan values\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "df.drop_duplicates(subset=list(set(df.columns) - set([dataset.timestamp_col, dataset.flow_id_col])), keep=\"first\", inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Properties\n",
    "\n",
    "calculating main dataset properties and saving them in a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = len(df)\n",
    "\n",
    "properties = {\n",
    "    \"name\": dataset.name,\n",
    "    \"length\": total_count,\n",
    "}\n",
    "\n",
    "num_benign = len(df[df['Label'] == 0])\n",
    "num_attack = len(df[df['Label'] == 1])\n",
    "\n",
    "properties[\"num_benign\"] = num_benign\n",
    "properties[\"percentage_of_benign_records\"] = ((num_benign * 100)/total_count)\n",
    "\n",
    "properties[\"num_attack\"] = num_attack\n",
    "properties[\"percentage_of_attack_records\"] = ((num_attack * 100)/total_count)\n",
    "\n",
    "properties[\"attacks\"] = list(df[\"Attack\"].unique())  # .to_list()\n",
    "\n",
    "filename = ('./datasets_properties/{}.json'.format(dataset.name))\n",
    "outfile = open(filename, 'w')\n",
    "outfile.writelines(json.dumps(properties))\n",
    "outfile.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Graph Construction\n",
    "\n",
    "Graph construction from the records in the dataset.<br>\n",
    "Nodes are specified by IP addresses. <br>\n",
    "If there exists atleast one network flow between two different IP addresses, an edge will be created. <br>\n",
    "Another way can be considered is to use MultiDiGraph class. However, some centralities will not work in addition to transitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(\n",
    "        df,\n",
    "        source=dataset.src_ip_col,\n",
    "        target=dataset.dst_ip_col,\n",
    "        create_using=nx.DiGraph()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.remove_nodes_from(list(nx.isolates(G)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying the communities in the graph using the methods get_communities. <br>\n",
    "Since communities can be calculated using different methods, and we want to use get communites at different stages of the code, we implemented it in a separate file, so a change will be done one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'bayanpy', 'infomap', 'graph_tool', 'wurlitzer', 'leidenalg'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'pyclustering', 'ASLPAw'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'leidenalg', 'infomap', 'wurlitzer'}\n",
      "==>> com: 130240\n",
      "==>> com: 4160\n",
      "==>> com: 1908\n",
      "==>> com: 1040\n",
      "==>> com: 1014\n",
      "==>> com: 469\n",
      "==>> com: 390\n",
      "==>> com: 390\n",
      "==>> com: 382\n",
      "==>> com: 326\n",
      "==>> com: 233\n",
      "==>> com: 218\n",
      "==>> com: 171\n",
      "==>> com: 149\n",
      "==>> com: 142\n",
      "==>> com: 127\n",
      "==>> com: 123\n",
      "==>> com: 117\n",
      "==>> com: 108\n",
      "==>> com: 71\n",
      "==>> com: 70\n",
      "==>> com: 69\n",
      "==>> com: 69\n",
      "==>> com: 66\n",
      "==>> com: 60\n",
      "==>> com: 60\n",
      "==>> com: 59\n",
      "==>> com: 57\n",
      "==>> com: 49\n",
      "==>> com: 36\n",
      "==>> com: 32\n",
      "==>> com: 26\n",
      "==>> com: 26\n",
      "==>> com: 16\n",
      "==>> com: 13\n",
      "==>> com: 11\n",
      "==>> com: 9\n",
      "==>> com: 6\n",
      "==>> com: 6\n",
      "==>> com: 6\n",
      "==>> com: 6\n",
      "==>> com: 6\n",
      "==>> com: 6\n",
      "==>> com: 5\n",
      "==>> com: 4\n",
      "==>> com: 4\n",
      "==>> com: 4\n",
      "==>> com: 3\n",
      "==>> com: 3\n",
      "==>> com: 3\n",
      "==>> com: 3\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n"
     ]
    }
   ],
   "source": [
    "import igraph as ig\n",
    "G1 = ig.Graph.from_networkx(G)\n",
    "part = G1.community_infomap()\n",
    "\n",
    "communities = []\n",
    "for com in part:\n",
    "    communities.append([G1.vs[node_index]['label'] for node_index in com])\n",
    "\n",
    "print(f\"==>> number of communities: {len(communities)}\")\n",
    "for com in communities:\n",
    "    print(f\"==>> com: {len(com)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Complex Networks Measures Computation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Computing Graph-level Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = {}\n",
    "\n",
    "properties[\"number_of_nodes\"] = G.number_of_nodes()\n",
    "properties[\"number_of_edges\"] = G.number_of_edges()\n",
    "\n",
    "degrees = [degree for _, degree in G.degree()]\n",
    "properties[\"max_degree\"] = max(degrees)\n",
    "properties[\"avg_degree\"] = sum(degrees) / len(degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties[\"transitivity\"] = nx.transitivity(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties[\"density\"] =  nx.density(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming G is your graph and communities is a list of sets, where each set contains the nodes in a community\n",
    "\n",
    "# Step 1: Map each node to its community\n",
    "node_to_community = {}\n",
    "for community_index, community in enumerate(communities):\n",
    "    for node in community:\n",
    "        node_to_community[node] = community_index\n",
    "\n",
    "# Step 2: Count inter-cluster edges efficiently\n",
    "inter_cluster_edges = 0\n",
    "for u, v in G.edges():\n",
    "    # Directly check if u and v belong to different communities\n",
    "    if node_to_community[u] != node_to_community[v]:\n",
    "        inter_cluster_edges += 1\n",
    "\n",
    "\n",
    "properties[\"mixing_parameter\"] = inter_cluster_edges / G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties[\"modularity\"] = nx.community.modularity(G, communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number_of_nodes': 142669,\n",
       " 'number_of_edges': 352453,\n",
       " 'max_degree': 58036,\n",
       " 'avg_degree': 4.940849098262412,\n",
       " 'transitivity': 0.144479693894849,\n",
       " 'density': 1.7315898092993565e-05,\n",
       " 'mixing_parameter': 0.002181851197180901,\n",
       " 'modularity': 0.0722648512264962}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = ('./datasets_properties/{}.json'.format(\"graph_\" + name))\n",
    "outfile = open(filename, 'w')\n",
    "outfile.writelines(json.dumps(properties))\n",
    "outfile.close()\n",
    "\n",
    "properties"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the graph-level metrics, suitable complex networks should be specified and added to the corresponding dataset in the list in src.data.dataset_info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Computing Node-level Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_labels = {}\n",
    "for i, community in enumerate(communities):\n",
    "    for node in community:\n",
    "        community_labels[node] = i\n",
    "\n",
    "nx.set_node_attributes(G, community_labels, \"new_community\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting inter and itra graph, to calculate the local and global variations of each centrality\n",
    "from src.network.network_features import separate_graph\n",
    "\n",
    "intra_graph, inter_graph = separate_graph(G, communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated\n"
     ]
    }
   ],
   "source": [
    "from src.network.network_features import cal_betweenness_centrality\n",
    "\n",
    "if \"betweenness\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, cal_betweenness_centrality(G), \"betweenness\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated\n"
     ]
    }
   ],
   "source": [
    "if \"local_betweenness\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, cal_betweenness_centrality(intra_graph), \"local_betweenness\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"global_betweenness\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, cal_betweenness_centrality(inter_graph), \"global_betweenness\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated\n"
     ]
    }
   ],
   "source": [
    "if \"degree\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.degree_centrality(G), \"degree\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated\n"
     ]
    }
   ],
   "source": [
    "if \"local_degree\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.degree_centrality(intra_graph), \"local_degree\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"global_degree\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.degree_centrality(inter_graph), \"global_degree\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated\n"
     ]
    }
   ],
   "source": [
    "if \"eigenvector\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.eigenvector_centrality(G, max_iter=600), \"eigenvector\")\n",
    "    print(\"calculated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"local_eigenvector\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.eigenvector_centrality(intra_graph), \"local_eigenvector\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"global_eigenvector\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.eigenvector_centrality(inter_graph), \"global_eigenvector\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated\n"
     ]
    }
   ],
   "source": [
    "if \"closeness\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.closeness_centrality(G), \"closeness\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"local_closeness\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.closeness_centrality(intra_graph), \"local_closeness\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"global_closeness\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.closeness_centrality(inter_graph), \"global_closeness\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated\n"
     ]
    }
   ],
   "source": [
    "if \"pagerank\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.pagerank(G, alpha=0.85), \"pagerank\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated\n"
     ]
    }
   ],
   "source": [
    "if \"local_pagerank\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.pagerank(intra_graph, alpha=0.85), \"local_pagerank\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"global_pagerank\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.pagerank(inter_graph, alpha=0.85), \"global_pagerank\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated\n"
     ]
    }
   ],
   "source": [
    "from src.network.network_features import cal_k_core\n",
    "\n",
    "if \"k_core\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, cal_k_core(G), \"k_core\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated\n"
     ]
    }
   ],
   "source": [
    "from src.network.network_features import cal_k_truss\n",
    "if \"k_truss\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, cal_k_truss(G), \"k_truss\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated\n"
     ]
    }
   ],
   "source": [
    "from src.network.CommCentralityCode import comm_centreality\n",
    "\n",
    "if \"Comm\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, comm_centreality(G, community_labels), \"Comm\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.network.modularity_vitality import modularity_vitality\n",
    "\n",
    "if \"mv\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, modularity_vitality(G, part), \"mv\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G, graph_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Adding Complex Networks Features to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> features_dicts: ('betweenness', 142669)\n",
      "==>> features_dicts: ('local_betweenness', 142669)\n",
      "==>> features_dicts: ('degree', 142669)\n",
      "==>> features_dicts: ('local_degree', 142669)\n",
      "==>> features_dicts: ('eigenvector', 142669)\n",
      "==>> features_dicts: ('closeness', 142669)\n",
      "==>> features_dicts: ('pagerank', 142669)\n",
      "==>> features_dicts: ('local_pagerank', 142669)\n",
      "==>> features_dicts: ('k_core', 142669)\n",
      "==>> features_dicts: ('k_truss', 142669)\n",
      "==>> features_dicts: ('Comm', 142669)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     df[feature] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mapply(\n\u001b[0;32m      9\u001b[0m         \u001b[39mlambda\u001b[39;00m row: features_dicts[feature[\u001b[39m4\u001b[39m:]]\u001b[39m.\u001b[39mget(row[dataset\u001b[39m.\u001b[39msrc_ip_col], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[39mif\u001b[39;00m feature[:\u001b[39m3\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdst\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 11\u001b[0m     df[feature] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mapply(\n\u001b[0;32m     12\u001b[0m         \u001b[39mlambda\u001b[39;49;00m row: features_dicts[feature[\u001b[39m4\u001b[39;49m:]]\u001b[39m.\u001b[39;49mget(row[dataset\u001b[39m.\u001b[39;49mdst_ip_col], \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Administrateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9412\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9414\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m   9415\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   9416\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9421\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m   9422\u001b[0m )\n\u001b[1;32m-> 9423\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Administrateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    676\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\Administrateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 798\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    800\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\Administrateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:815\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    812\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    813\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m    814\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf(v)\n\u001b[1;32m--> 815\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    816\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    817\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    820\u001b[0m \u001b[39mreturn\u001b[39;00m results, res_index\n",
      "File \u001b[1;32mc:\\Users\\Administrateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\generic.py:42\u001b[0m, in \u001b[0;36mcreate_pandas_abc_type.<locals>._instancecheck\u001b[1;34m(cls, inst)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(inst, attr, \u001b[39m\"\u001b[39m\u001b[39m_typ\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39min\u001b[39;00m comp\n\u001b[0;32m     40\u001b[0m \u001b[39m# https://github.com/python/mypy/issues/1006\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39m# error: 'classmethod' used with a non-method\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[39m@classmethod\u001b[39m  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_instancecheck\u001b[39m(\u001b[39mcls\u001b[39m, inst) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[0;32m     44\u001b[0m     \u001b[39mreturn\u001b[39;00m _check(inst) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(inst, \u001b[39mtype\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[39m@classmethod\u001b[39m  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_subclasscheck\u001b[39m(\u001b[39mcls\u001b[39m, inst) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[0;32m     48\u001b[0m     \u001b[39m# Raise instead of returning False\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     \u001b[39m# This is consistent with default __subclasscheck__ behavior\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "features_dicts = {}\n",
    "for measure in dataset.cn_measures:\n",
    "    features_dicts[measure] = nx.get_node_attributes(G, measure)\n",
    "    print(f\"==>> features_dicts: {measure , len(features_dicts[measure])}\")\n",
    "    \n",
    "for feature in dataset.network_features:\n",
    "        if feature[:3] == \"src\":\n",
    "            df[feature] = df.apply(\n",
    "                lambda row: features_dicts[feature[4:]].get(row[dataset.src_ip_col], -1), axis=1)\n",
    "        if feature[:3] == \"dst\":\n",
    "            df[feature] = df.apply(\n",
    "                lambda row: features_dicts[feature[4:]].get(row[dataset.dst_ip_col], -1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow ID</th>\n",
       "      <th>Src IP</th>\n",
       "      <th>Src Port</th>\n",
       "      <th>Dst IP</th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>...</th>\n",
       "      <th>src_closeness</th>\n",
       "      <th>dst_closeness</th>\n",
       "      <th>src_pagerank</th>\n",
       "      <th>dst_pagerank</th>\n",
       "      <th>src_local_pagerank</th>\n",
       "      <th>dst_local_pagerank</th>\n",
       "      <th>src_k_truss</th>\n",
       "      <th>dst_k_truss</th>\n",
       "      <th>src_Comm</th>\n",
       "      <th>dst_Comm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>177.30.87.144-192.168.1.1-0-0-0</td>\n",
       "      <td>177.30.87.144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.168.1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25/04/2019 05:18:52 pm</td>\n",
       "      <td>47814343.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.206533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>167.49.176.28-50.165.192.168-0-0-0</td>\n",
       "      <td>167.49.176.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.165.192.168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25/04/2019 05:18:49 pm</td>\n",
       "      <td>2033142.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.022607</td>\n",
       "      <td>0.937518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>230.158.52.59-177.21.192.168-0-0-0</td>\n",
       "      <td>230.158.52.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.21.192.168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25/04/2019 05:18:37 pm</td>\n",
       "      <td>82877133.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002727</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.021332</td>\n",
       "      <td>0.997455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183.68.192.168-1.1.192.168-0-0-0</td>\n",
       "      <td>183.68.192.168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1.192.168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25/04/2019 05:18:42 pm</td>\n",
       "      <td>24359.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.470284</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.061140</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.018961</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.037681</td>\n",
       "      <td>0.229036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183.41.192.168-1.1.192.168-0-0-0</td>\n",
       "      <td>183.41.192.168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1.192.168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25/04/2019 05:18:42 pm</td>\n",
       "      <td>10239351.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.470284</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.061140</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.018961</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.037681</td>\n",
       "      <td>0.229036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Flow ID          Src IP  Src Port  \\\n",
       "0     177.30.87.144-192.168.1.1-0-0-0   177.30.87.144       0.0   \n",
       "1  167.49.176.28-50.165.192.168-0-0-0   167.49.176.28       0.0   \n",
       "2  230.158.52.59-177.21.192.168-0-0-0   230.158.52.59       0.0   \n",
       "3    183.68.192.168-1.1.192.168-0-0-0  183.68.192.168       0.0   \n",
       "4    183.41.192.168-1.1.192.168-0-0-0  183.41.192.168       0.0   \n",
       "\n",
       "           Dst IP  Dst Port  Protocol               Timestamp  Flow Duration  \\\n",
       "0     192.168.1.1       0.0       0.0  25/04/2019 05:18:52 pm     47814343.0   \n",
       "1  50.165.192.168       0.0       0.0  25/04/2019 05:18:49 pm      2033142.0   \n",
       "2  177.21.192.168       0.0       0.0  25/04/2019 05:18:37 pm     82877133.0   \n",
       "3     1.1.192.168       0.0       0.0  25/04/2019 05:18:42 pm        24359.0   \n",
       "4     1.1.192.168       0.0       0.0  25/04/2019 05:18:42 pm     10239351.0   \n",
       "\n",
       "   Tot Fwd Pkts  Tot Bwd Pkts  ...  src_closeness  dst_closeness  \\\n",
       "0           5.0           0.0  ...            0.0       0.001293   \n",
       "1           2.0           0.0  ...            0.0       0.000105   \n",
       "2          14.0           0.0  ...            0.0       0.002727   \n",
       "3           2.0           0.0  ...            0.0       0.470284   \n",
       "4           3.0           0.0  ...            0.0       0.470284   \n",
       "\n",
       "   src_pagerank  dst_pagerank  src_local_pagerank  dst_local_pagerank  \\\n",
       "0      0.000002      0.000021            0.000003            0.000015   \n",
       "1      0.000002      0.000029            0.000004            0.000055   \n",
       "2      0.000002      0.000709            0.000004            0.001335   \n",
       "3      0.000002      0.061140            0.000004            0.018961   \n",
       "4      0.000002      0.061140            0.000004            0.018961   \n",
       "\n",
       "   src_k_truss  dst_k_truss  src_Comm  dst_Comm  \n",
       "0     0.000210     0.001051  0.001453  0.206533  \n",
       "1     0.000210     0.000315  0.022607  0.937518  \n",
       "2     0.000210     0.000526  0.021332  0.997455  \n",
       "3     0.000420     0.000631  0.037681  0.229036  \n",
       "4     0.000526     0.000631  0.037681  0.229036  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(df, new_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
