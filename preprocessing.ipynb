{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing file for data cleaning and transformation before analysis.\n",
    "This notebook includes code for:\n",
    "1. Data loading and cleaning\n",
    "2. Graph Construction\n",
    "3. Complex Networks Measures Computation\n",
    "4. Adding Complex Networks Features to the dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# datasets is a list of available datasets descriptions containing: path, key columns names, and suitable complex network features\n",
    "from src.data.dataset_info import datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: cic_ton_iot\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets[0]\n",
    "name = dataset.name\n",
    "print(\"dataset: {}\".format(name))\n",
    "\n",
    "path = \"./datasets/original/{}.pkl\".format(name)\n",
    "new_path = \"./datasets/preprocessed/{}.pkl\".format(name)\n",
    "graph_path = \"./datasets/preprocessed/graph_{}.gexf\".format(name)\n",
    "df = pd.read_pickle(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping infinity values, Nan values, and duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting all infinity values into nan then dropping all records containing nan values\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "df.drop_duplicates(subset=list(set(df.columns) - set([dataset.timestamp_col, dataset.flow_id_col])), keep=\"first\", inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Properties\n",
    "\n",
    "calculating main dataset properties and saving them in a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = len(df)\n",
    "\n",
    "properties = {\n",
    "    \"name\": dataset.name,\n",
    "    \"length\": total_count,\n",
    "}\n",
    "\n",
    "num_benign = len(df[df['Label'] == 0])\n",
    "num_attack = len(df[df['Label'] == 1])\n",
    "\n",
    "properties[\"num_benign\"] = num_benign\n",
    "properties[\"percentage_of_benign_records\"] = ((num_benign * 100)/total_count)\n",
    "\n",
    "properties[\"num_attack\"] = num_attack\n",
    "properties[\"percentage_of_attack_records\"] = ((num_attack * 100)/total_count)\n",
    "\n",
    "properties[\"attacks\"] = list(df[\"Attack\"].unique())  # .to_list()\n",
    "\n",
    "filename = ('./datasets_properties/{}.json'.format(dataset.name))\n",
    "outfile = open(filename, 'w')\n",
    "outfile.writelines(json.dumps(properties))\n",
    "outfile.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Graph Construction\n",
    "\n",
    "Graph construction from the records in the dataset.<br>\n",
    "Nodes are specified by IP addresses. <br>\n",
    "If there exists atleast one network flow between two different IP addresses, an edge will be created. <br>\n",
    "Another way can be considered is to use MultiDiGraph class. However, some centralities will not work in addition to transitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(\n",
    "        df,\n",
    "        source=dataset.src_ip_col,\n",
    "        target=dataset.dst_ip_col,\n",
    "        create_using=nx.DiGraph()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.remove_nodes_from(list(nx.isolates(G)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying the communities in the graph using the methods get_communities. <br>\n",
    "Since communities can be calculated using different methods, and we want to use get communites at different stages of the code, we implemented it in a separate file, so a change will be done one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> number of communities: 100\n",
      "==>> com: 69\n",
      "==>> com: 16\n",
      "==>> com: 390\n",
      "==>> com: 130242\n",
      "==>> com: 27\n",
      "==>> com: 5\n",
      "==>> com: 1040\n",
      "==>> com: 60\n",
      "==>> com: 127\n",
      "==>> com: 6\n",
      "==>> com: 117\n",
      "==>> com: 2\n",
      "==>> com: 59\n",
      "==>> com: 70\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 142\n",
      "==>> com: 2\n",
      "==>> com: 171\n",
      "==>> com: 4160\n",
      "==>> com: 2\n",
      "==>> com: 3\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 9\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 108\n",
      "==>> com: 218\n",
      "==>> com: 390\n",
      "==>> com: 2\n",
      "==>> com: 1014\n",
      "==>> com: 26\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 49\n",
      "==>> com: 233\n",
      "==>> com: 4\n",
      "==>> com: 2\n",
      "==>> com: 57\n",
      "==>> com: 6\n",
      "==>> com: 2\n",
      "==>> com: 3\n",
      "==>> com: 2\n",
      "==>> com: 66\n",
      "==>> com: 2\n",
      "==>> com: 6\n",
      "==>> com: 2\n",
      "==>> com: 469\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 382\n",
      "==>> com: 326\n",
      "==>> com: 2\n",
      "==>> com: 11\n",
      "==>> com: 60\n",
      "==>> com: 71\n",
      "==>> com: 3\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 4\n",
      "==>> com: 2\n",
      "==>> com: 1908\n",
      "==>> com: 69\n",
      "==>> com: 36\n",
      "==>> com: 123\n",
      "==>> com: 26\n",
      "==>> com: 149\n",
      "==>> com: 2\n",
      "==>> com: 6\n",
      "==>> com: 2\n",
      "==>> com: 6\n",
      "==>> com: 13\n",
      "==>> com: 5\n",
      "==>> com: 4\n",
      "==>> com: 2\n",
      "==>> com: 6\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 3\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n",
      "==>> com: 2\n"
     ]
    }
   ],
   "source": [
    "import igraph as ig\n",
    "G1 = ig.Graph.from_networkx(G)\n",
    "part = G1.community_infomap()\n",
    "\n",
    "communities = []\n",
    "for com in part:\n",
    "    communities.append([G1.vs[node_index]['_nx_name'] for node_index in com])\n",
    "\n",
    "print(f\"==>> number of communities: {len(communities)}\")\n",
    "for com in communities:\n",
    "    print(f\"==>> com: {len(com)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Complex Networks Measures Computation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Computing Graph-level Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = {}\n",
    "\n",
    "properties[\"number_of_nodes\"] = G.number_of_nodes()\n",
    "properties[\"number_of_edges\"] = G.number_of_edges()\n",
    "\n",
    "degrees = [degree for _, degree in G.degree()]\n",
    "properties[\"max_degree\"] = max(degrees)\n",
    "properties[\"avg_degree\"] = sum(degrees) / len(degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties[\"transitivity\"] = nx.transitivity(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties[\"density\"] =  nx.density(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming G is your graph and communities is a list of sets, where each set contains the nodes in a community\n",
    "\n",
    "# Step 1: Map each node to its community\n",
    "node_to_community = {}\n",
    "for community_index, community in enumerate(communities):\n",
    "    for node in community:\n",
    "        node_to_community[node] = community_index\n",
    "\n",
    "# Step 2: Count inter-cluster edges efficiently\n",
    "inter_cluster_edges = 0\n",
    "for u, v in G.edges():\n",
    "    # Directly check if u and v belong to different communities\n",
    "    if node_to_community[u] != node_to_community[v]:\n",
    "        inter_cluster_edges += 1\n",
    "\n",
    "\n",
    "properties[\"mixing_parameter\"] = inter_cluster_edges / G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties[\"modularity\"] = nx.community.modularity(G, communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number_of_nodes': 142669,\n",
       " 'number_of_edges': 352453,\n",
       " 'max_degree': 58036,\n",
       " 'avg_degree': 4.940849098262412,\n",
       " 'transitivity': 0.144479693894849,\n",
       " 'density': 1.7315898092993565e-05,\n",
       " 'mixing_parameter': 0.002164827650778969,\n",
       " 'modularity': 0.07225186954453378}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = ('./datasets_properties/{}.json'.format(\"graph_\" + name))\n",
    "outfile = open(filename, 'w')\n",
    "outfile.writelines(json.dumps(properties))\n",
    "outfile.close()\n",
    "\n",
    "properties"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the graph-level metrics, suitable complex networks should be specified and added to the corresponding dataset in the list in src.data.dataset_info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Computing Node-level Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_labels = {}\n",
    "for i, community in enumerate(communities):\n",
    "    for node in community:\n",
    "        community_labels[node] = i\n",
    "\n",
    "nx.set_node_attributes(G, community_labels, \"new_community\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting inter and itra graph, to calculate the local and global variations of each centrality\n",
    "from src.network.network_features import separate_graph\n",
    "\n",
    "intra_graph, inter_graph = separate_graph(G, communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated\n"
     ]
    }
   ],
   "source": [
    "from src.network.network_features import cal_betweenness_centrality\n",
    "\n",
    "if \"betweenness\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, cal_betweenness_centrality(G), \"betweenness\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated\n"
     ]
    }
   ],
   "source": [
    "if \"local_betweenness\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, cal_betweenness_centrality(intra_graph), \"local_betweenness\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"global_betweenness\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, cal_betweenness_centrality(inter_graph), \"global_betweenness\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated\n"
     ]
    }
   ],
   "source": [
    "if \"degree\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.degree_centrality(G), \"degree\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated\n"
     ]
    }
   ],
   "source": [
    "if \"local_degree\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.degree_centrality(intra_graph), \"local_degree\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"global_degree\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.degree_centrality(inter_graph), \"global_degree\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated\n"
     ]
    }
   ],
   "source": [
    "if \"eigenvector\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.eigenvector_centrality(G, max_iter=600), \"eigenvector\")\n",
    "    print(\"calculated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"local_eigenvector\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.eigenvector_centrality(intra_graph), \"local_eigenvector\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"global_eigenvector\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.eigenvector_centrality(inter_graph), \"global_eigenvector\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated\n"
     ]
    }
   ],
   "source": [
    "if \"closeness\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.closeness_centrality(G), \"closeness\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"local_closeness\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.closeness_centrality(intra_graph), \"local_closeness\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"global_closeness\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.closeness_centrality(inter_graph), \"global_closeness\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated\n"
     ]
    }
   ],
   "source": [
    "if \"pagerank\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.pagerank(G, alpha=0.85), \"pagerank\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated\n"
     ]
    }
   ],
   "source": [
    "if \"local_pagerank\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.pagerank(intra_graph, alpha=0.85), \"local_pagerank\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"global_pagerank\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, nx.pagerank(inter_graph, alpha=0.85), \"global_pagerank\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated\n"
     ]
    }
   ],
   "source": [
    "from src.network.network_features import cal_k_core\n",
    "\n",
    "if \"k_core\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, cal_k_core(G), \"k_core\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated\n"
     ]
    }
   ],
   "source": [
    "from src.network.network_features import cal_k_truss\n",
    "if \"k_truss\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, cal_k_truss(G), \"k_truss\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated\n"
     ]
    }
   ],
   "source": [
    "from src.network.CommCentralityCode import comm_centreality\n",
    "\n",
    "if \"Comm\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, comm_centreality(G, community_labels), \"Comm\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.network.modularity_vitality import modularity_vitality\n",
    "\n",
    "if \"mv\" in dataset.cn_measures:\n",
    "    nx.set_node_attributes(G, modularity_vitality(G, part), \"mv\")\n",
    "    print(\"calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G, graph_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Adding Complex Networks Features to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> features_dicts: ('betweenness', 142669)\n",
      "==>> features_dicts: ('local_betweenness', 142669)\n",
      "==>> features_dicts: ('degree', 142669)\n",
      "==>> features_dicts: ('local_degree', 142669)\n",
      "==>> features_dicts: ('eigenvector', 142669)\n",
      "==>> features_dicts: ('closeness', 142669)\n",
      "==>> features_dicts: ('pagerank', 142669)\n",
      "==>> features_dicts: ('local_pagerank', 142669)\n",
      "==>> features_dicts: ('k_core', 142669)\n",
      "==>> features_dicts: ('k_truss', 142669)\n",
      "==>> features_dicts: ('Comm', 142669)\n"
     ]
    }
   ],
   "source": [
    "features_dicts = {}\n",
    "for measure in dataset.cn_measures:\n",
    "    features_dicts[measure] = nx.get_node_attributes(G, measure)\n",
    "    print(f\"==>> features_dicts: {measure , len(features_dicts[measure])}\")\n",
    "    \n",
    "for feature in dataset.network_features:\n",
    "        if feature[:3] == \"src\":\n",
    "            df[feature] = df.apply(\n",
    "                lambda row: features_dicts[feature[4:]].get(row[dataset.src_ip_col], -1), axis=1)\n",
    "        if feature[:3] == \"dst\":\n",
    "            df[feature] = df.apply(\n",
    "                lambda row: features_dicts[feature[4:]].get(row[dataset.dst_ip_col], -1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow ID</th>\n",
       "      <th>Src IP</th>\n",
       "      <th>Src Port</th>\n",
       "      <th>Dst IP</th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>...</th>\n",
       "      <th>src_pagerank</th>\n",
       "      <th>dst_pagerank</th>\n",
       "      <th>src_local_pagerank</th>\n",
       "      <th>dst_local_pagerank</th>\n",
       "      <th>src_k_core</th>\n",
       "      <th>dst_k_core</th>\n",
       "      <th>src_k_truss</th>\n",
       "      <th>dst_k_truss</th>\n",
       "      <th>src_Comm</th>\n",
       "      <th>dst_Comm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>177.30.87.144-192.168.1.1-0-0-0</td>\n",
       "      <td>177.30.87.144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.168.1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25/04/2019 05:18:52 pm</td>\n",
       "      <td>47814343.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.231202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>167.49.176.28-50.165.192.168-0-0-0</td>\n",
       "      <td>167.49.176.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.165.192.168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25/04/2019 05:18:49 pm</td>\n",
       "      <td>2033142.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.030364</td>\n",
       "      <td>0.937725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>230.158.52.59-177.21.192.168-0-0-0</td>\n",
       "      <td>230.158.52.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.21.192.168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25/04/2019 05:18:37 pm</td>\n",
       "      <td>82877133.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.028652</td>\n",
       "      <td>0.997676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183.68.192.168-1.1.192.168-0-0-0</td>\n",
       "      <td>183.68.192.168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1.192.168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25/04/2019 05:18:42 pm</td>\n",
       "      <td>24359.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.061140</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.007412</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.010413</td>\n",
       "      <td>0.031110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183.41.192.168-1.1.192.168-0-0-0</td>\n",
       "      <td>183.41.192.168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1.192.168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25/04/2019 05:18:42 pm</td>\n",
       "      <td>10239351.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.061140</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.007412</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.018223</td>\n",
       "      <td>0.031110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Flow ID          Src IP  Src Port  \\\n",
       "0     177.30.87.144-192.168.1.1-0-0-0   177.30.87.144       0.0   \n",
       "1  167.49.176.28-50.165.192.168-0-0-0   167.49.176.28       0.0   \n",
       "2  230.158.52.59-177.21.192.168-0-0-0   230.158.52.59       0.0   \n",
       "3    183.68.192.168-1.1.192.168-0-0-0  183.68.192.168       0.0   \n",
       "4    183.41.192.168-1.1.192.168-0-0-0  183.41.192.168       0.0   \n",
       "\n",
       "           Dst IP  Dst Port  Protocol               Timestamp  Flow Duration  \\\n",
       "0     192.168.1.1       0.0       0.0  25/04/2019 05:18:52 pm     47814343.0   \n",
       "1  50.165.192.168       0.0       0.0  25/04/2019 05:18:49 pm      2033142.0   \n",
       "2  177.21.192.168       0.0       0.0  25/04/2019 05:18:37 pm     82877133.0   \n",
       "3     1.1.192.168       0.0       0.0  25/04/2019 05:18:42 pm        24359.0   \n",
       "4     1.1.192.168       0.0       0.0  25/04/2019 05:18:42 pm     10239351.0   \n",
       "\n",
       "   Tot Fwd Pkts  Tot Bwd Pkts  ...  src_pagerank  dst_pagerank  \\\n",
       "0           5.0           0.0  ...      0.000002      0.000021   \n",
       "1           2.0           0.0  ...      0.000002      0.000029   \n",
       "2          14.0           0.0  ...      0.000002      0.000709   \n",
       "3           2.0           0.0  ...      0.000002      0.061140   \n",
       "4           3.0           0.0  ...      0.000002      0.061140   \n",
       "\n",
       "   src_local_pagerank  dst_local_pagerank  src_k_core  dst_k_core  \\\n",
       "0            0.000002            0.000018    0.090909    1.000000   \n",
       "1            0.000004            0.000055    0.090909    0.181818   \n",
       "2            0.000004            0.001335    0.090909    0.363636   \n",
       "3            0.000003            0.007412    0.363636    0.818182   \n",
       "4            0.000005            0.007412    0.636364    0.818182   \n",
       "\n",
       "   src_k_truss  dst_k_truss  src_Comm  dst_Comm  \n",
       "0     0.000210     0.001051  0.001926  0.231202  \n",
       "1     0.000210     0.000315  0.030364  0.937725  \n",
       "2     0.000210     0.000526  0.028652  0.997676  \n",
       "3     0.000420     0.000631  0.010413  0.031110  \n",
       "4     0.000526     0.000631  0.018223  0.031110  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(df, new_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
