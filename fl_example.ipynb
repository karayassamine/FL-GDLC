{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr.client import ClientApp\n",
    "from flwr.server import ServerApp\n",
    "from flwr.common import Context\n",
    "import flwr as fl\n",
    "from flwr.server import ServerAppComponents, ServerConfig\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers, models, Input, regularizers, callbacks, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    \"src_ip\": [f\"192.168.0.{i%3}\" for i in range(20)],\n",
    "    \"dst_ip\": [f\"10.0.0.{i%2}\" for i in range(20)],\n",
    "    \"timestamp\": pd.date_range(\"2021-01-01\", periods=20, freq=\"min\").strftime(\"%d/%m/%Y %I:%M:%S %p\"),\n",
    "    \"flow_id\": list(range(20)),\n",
    "    \"f1\": [random.randint(0, 100) for _ in range(20)],\n",
    "    \"f2\": [random.randint(0, 100) for _ in range(20)],\n",
    "    \"f3\": [random.randint(0, 100) for _ in range(20)],\n",
    "    \"f4\": [random.randint(0, 100) for _ in range(20)],\n",
    "    \"f5\": [random.randint(0, 100) for _ in range(20)],\n",
    "    \"f6\": [random.randint(0, 100) for _ in range(20)],\n",
    "    \"class\": [\"Benign\"] * 6 + [\"bot\"] * 8 + [\"dos\"] * 6,\n",
    "    \"label\": [0] * 6 + [1] * 14\n",
    "})\n",
    "df2 = pd.DataFrame({\n",
    "    \"src_ip\": [f\"192.168.1.{i%4}\" for i in range(20)],\n",
    "    \"dst_ip\": [f\"10.0.1.{i%3}\" for i in range(20)],\n",
    "    \"timestamp\": pd.date_range(\"2021-02-01\", periods=20, freq=\"min\").strftime(\"%d/%m/%Y %I:%M:%S %p\"),\n",
    "    \"flow_id\": list(range(20)),\n",
    "    \"f1\": [random.randint(0, 100) for _ in range(20)],\n",
    "    \"f2\": [random.randint(0, 100) for _ in range(20)],\n",
    "    \"f3\": [random.randint(0, 100) for _ in range(20)],\n",
    "    \"f4\": [random.randint(0, 100) for _ in range(20)],\n",
    "    \"f5\": [random.randint(0, 100) for _ in range(20)],\n",
    "    \"f6\": [random.randint(0, 100) for _ in range(20)],\n",
    "    \"class\": [\"Benign\"] * 10 + [\"bot\"] * 10,\n",
    "    \"label\": [0] * 10 + [1] * 10\n",
    "})\n",
    "\n",
    "df3 = pd.DataFrame({\n",
    "    \"src_ip\": [f\"192.168.1.{i%4}\" for i in range(10)],\n",
    "    \"dst_ip\": [f\"10.0.1.{i%3}\" for i in range(10)],\n",
    "    \"timestamp\": pd.date_range(\"2021-02-01\", periods=10, freq=\"min\").strftime(\"%d/%m/%Y %I:%M:%S %p\"),\n",
    "    \"flow_id\": list(range(10)),\n",
    "    \"f1\": [random.randint(0, 100) for _ in range(10)],\n",
    "    \"f2\": [random.randint(0, 100) for _ in range(10)],\n",
    "    \"f3\": [random.randint(0, 100) for _ in range(10)],\n",
    "    \"f4\": [random.randint(0, 100) for _ in range(10)],\n",
    "    \"f5\": [random.randint(0, 100) for _ in range(10)],\n",
    "    \"f6\": [random.randint(0, 100) for _ in range(10)],\n",
    "    \"class\": [\"Benign\"] * 5 + [\"bot\"] * 3 + [\"dos\"] * 2,\n",
    "    \"label\": [0] * 5 + [1] * 5\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model(input_shape, alpha = 0.001):\n",
    "    LAMBD_2 = 0.001\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Conv1D(80, kernel_size=3,\n",
    "                activation=\"relu\", input_shape=(input_shape, 1), kernel_regularizer=regularizers.L2(l2=LAMBD_2)))\n",
    "    model.add(layers.MaxPooling1D())\n",
    "    model.add(layers.LayerNormalization(axis=1))\n",
    "    # .L1L2(l1=LAMBD_1, l2=LAMBD_2)\n",
    "    model.add(layers.Conv1D(80, 3, activation='relu', kernel_regularizer=regularizers.L2(l2=LAMBD_2)))\n",
    "    model.add(layers.MaxPooling1D())\n",
    "    model.add(layers.LayerNormalization(axis=1))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(200,activation='relu', kernel_regularizer=regularizers.L2(l2=LAMBD_2)))\n",
    "    model.add(layers.LayerNormalization(axis=1))\n",
    "    model.add(layers.Dense(200,activation='relu', kernel_regularizer=regularizers.L2(l2=LAMBD_2)))\n",
    "    model.add(layers.LayerNormalization(axis=1))\n",
    "    model.add(layers.Dense(80,activation='relu', kernel_regularizer=regularizers.L2(l2=LAMBD_2)))\n",
    "    model.add(layers.LayerNormalization(axis=1))\n",
    "\n",
    "    model.add(layers.Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=alpha),\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLClient(fl.client.NumPyClient):\n",
    "    def __init__(self, context, X_train, X_val, y_train, y_val, model, num_local_epochs):\n",
    "\n",
    "        self.context = context\n",
    "        self.X_train = X_train\n",
    "        self.X_val = X_val\n",
    "        self.y_train = y_train\n",
    "        self.y_val = y_val\n",
    "        \n",
    "        self.model = model\n",
    "        self.num_local_epochs = num_local_epochs\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        self.model.set_weights(parameters)\n",
    "        \n",
    "    def fit(self, parameters, config):\n",
    "\n",
    "        lr=0.001\n",
    "        self.model = create_keras_model(input_shape=self.input_dim, alpha=lr)\n",
    "        self.set_parameters(parameters, config)\n",
    "\n",
    "        history = self.model.fit(self.x_train, self.y_train,\n",
    "                                epochs=config[\"local_epochs\"],\n",
    "                                batch_size=config[\"batch_size\"],\n",
    "                                validation_data=(self.x_val, self.y_val),  \n",
    "                                verbose=0)\n",
    "\n",
    "        return self.get_parameters(config), len(self.x_train), {k: v[-1] for k, v in history.history.items()}\n",
    "\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters, config)\n",
    "        loss, accuracy = self.model.evaluate(self.X_val, self.y_val, 2, verbose=0)\n",
    "        return loss, len(self.X_val), {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_client_fn(data, labels):\n",
    "\n",
    "    def client_fn(context: Context):\n",
    "\n",
    "        client_id = int(context.node_config[\"partition-id\"])\n",
    "        print(f\"==>> client_id: {client_id}\")\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            data[client_id], labels[client_id], test_size=0.1, random_state=1)\n",
    "\n",
    "        print(f\"==>> X_train: {X_train}\")\n",
    "        print(f\"==>> X_val: {X_val}\")\n",
    "        \n",
    "        \n",
    "        model = create_keras_model(6)\n",
    "\n",
    "        return FLClient(\n",
    "            context, np.array(X_train), np.array(X_val), np.array(y_train), np.array(y_val), model, 1\n",
    "        ).to_client()\n",
    "\n",
    "    return client_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_data = [\n",
    "    df1[[\"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\"]],\n",
    "    df2[[\"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\"]]\n",
    "]\n",
    "# print(f\"==>> clients_data: {clients_data}\")\n",
    "clients_labels = [\n",
    "    df1[\"class\"],\n",
    "    df2[\"class\"]\n",
    "]\n",
    "# print(f\"==>> clients_labels: {clients_labels}\")\n",
    "client_app = ClientApp(client_fn=generate_client_fn(\n",
    "    clients_data, clients_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluate_fn(x_test_server, y_test_server):\n",
    "    def evaluate_fn(server_round: int, parameters, config):\n",
    "        eval_model = create_keras_model(input_shape=6)\n",
    "        eval_model.set_weights(parameters)\n",
    "\n",
    "        test_loss, test_acc = eval_model.evaluate(x_test_server, y_test_server,\n",
    "                                                  batch_size = 2)\n",
    "        \n",
    "        results_dict = {\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_acc\": test_acc,\n",
    "            \"round\": server_round\n",
    "        }\n",
    "\n",
    "        return results_dict\n",
    "\n",
    "    return evaluate_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_on_fit_config():\n",
    "\n",
    "    def fit_config_fn(server_round: int):\n",
    "        return {\n",
    "            \"lr\": 0.001,\n",
    "            \"local_epochs\": 1,\n",
    "            \"batch_size\": 2,\n",
    "        }\n",
    "\n",
    "    return fit_config_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_server_fn(data, labels):\n",
    "    def server_fn(context: Context):\n",
    "        strategy=fl.server.strategy.FedAvg(\n",
    "            fraction_fit=1.0,  # in simulation, since all clients are available at all times, we can just use `min_fit_clients` to control exactly how many clients we want to involve during fit\n",
    "            min_fit_clients=len(clients_data),  # number of clients to sample for fit()\n",
    "            fraction_evaluate=0.0,  # similar to fraction_fit, we don't need to use this argument.\n",
    "            min_evaluate_clients=0,  # number of clients to sample for evaluate()\n",
    "            min_available_clients=len(clients_data),\n",
    "            on_fit_config_fn=get_on_fit_config(),  # a function to execute to obtain the configuration to send to the clients during fit()\n",
    "            evaluate_fn=get_evaluate_fn(data, labels),\n",
    "        )\n",
    "        \n",
    "        return ServerAppComponents(\n",
    "            strategy=strategy,\n",
    "            config=ServerConfig(num_rounds=2)\n",
    "        )\n",
    "\n",
    "    return server_fn\n",
    "server_app = ServerApp(server_fn=generate_server_fn(df3[[\"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\"]], df3[\"class\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simulation(\n",
    "    server_app=server_app,\n",
    "    client_app=client_app,\n",
    "    num_supernodes=2,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
